# 1.自我介绍
你好，很高兴有机会参加你们公司的面试。我是21年毕业的，大学学的专业就是计算机科学与技术，
毕业后入职xxx公司，主要是在xxx团队担任后端开发的角色，先后参与过多个项目设计、开发工作。
日常工作的话主要是使用 go 语言进行开发，涉及技术栈包括 mysql 、 saturn 、kafka、 
redis 等。


你的话我建议你可以找一下：
1，抗压能力：在多个并发高优需求下，能够很高质量地有序完成所有需求，并做好个人管理
2，学习能力：在项目不断发展地过程中，你还不断地去补相关知识，以解决遇到的问题（比
如你是不是没有提，在搞python proxy时，你的header处理那部分？就返回的body一大
就导致报错的那个）
3，个人的主动性

# 2.项目介绍
## 2.1 出库模块
### 2.1.1 模块的功能
介绍：和国内所有快递业务一样，运单到达网点后，需要先进行收货，然后根据运单的数据，判断货物流向。
站内操作人员会先进行站内收货动作，收完货后，会对订单进行分拣打包。 打包时，操作人员扫描订单号后，
传给后端进行代码逻辑判断，判断是否是同一个转运类型和转运目的地。如果相同，则可以加入到同一个转运
包中。打包好后就进行交接给下游（干线运输、派送或交接给第三方物流商）。当然了，也涉及逆向流程，也
就是发起回退的流程，也同样是类似的操作，站点收货、交接。所以站内这个团队被划分为入库、出库、操作
作业单、容器、分拣机几个领域。我主要是负责打包这个模块的业务。打包模块涉及交互的领域非常多，所以
我们打包的调用链路在业务本身上就是很长的，我们核心作业接口面向的使用方主要是两个：站内操作人员以
及分拣机。

主要工作：我在这边做的最核心的一个项目就是进行了打包模块的重构。
1. 在mentor的帮助下设计并开发了一个基于DAG图的编排框架，用于将打包的各个流程进行编排，通过go
协程来异步执行各个没有依赖的流程；
2. 与产品共同厘清了打包流程中不同市场的校验逻辑，并整理出了完整的文档；
3. 重构后的代码简单易读，可维护性很高，并且增加了完整的单元测试，保证程序的可靠性；
4. 设计并开发除了基于日志的对账以及告警功能，在上线前通过对账的方式保证重构逻辑的正确性，通过一
段时间的验证后顺利完成了新代码的灰度以及切流；

代码大体逻辑是：根据调用方传入的订单号、查询运单信息、调用其他
第三方（路由、计费、收货、派送等各个域进行相关的校验）、调用容器服务将打包信息落库、查询并组装渲
染数据返回给调用方。

### 2.1.2 进行重构的原因是什么
1. 代码逻辑很混乱，可读性很差，非常难以维护。主要体现在：
- 代码中的重复的地方很多，相同功能有不同的实现，没有通用性、代码复杂度高，特别是判断转运包类型的逻辑，使
用了非常多的if else嵌套，很难维护

使用了策略模式对这部分代码重构，定义了一个 TOStrategy 的接口，它主要包括两个方法， isMatch()  process() 两个方法，
isMatch 是各个类型的TO 的具体判断逻辑， process 是对应需要执行的装填数据、以及校验的逻辑。
> 策略模式是一种行为设计模式，它定义了一系列算法，并将每个算法封装在一个具有共同接口的类中，使得它们可以相互替换。策略模式让算法独立于使用它的

另外，还使用了一个责任链的模式来处理各个市场不同的校验内容。
主要是定义一个校验器的接口，以及一个执行链，校验器主要包括： Name() 用于获取校验器名称，和 Validate() 用于执行校验逻辑 两个方法，在
执行链中，通过apollo 配置了需要执行的校验器 （一个校验器接口的slice, 根据apollo配置进行append），最后通过遍历执行责任链上面各个校验器的校验方法
> 责任链模式（Chain of Responsibility）也是一种行为设计模式，它是一种处理请求的模式，它让多个处理器都有机会处理该请求，直到其中某个处理成功为止。责任链模式把多个处理器串成链，然后让请求在链上传递

- 滥用指针，打包的流程依赖订单这个实体数据，代码采用指针的方式进行整个链路的传递，导致这个数据中途被改
了都无法发现；
- 接口设计不合理，接口是面向SQL 编程的，入参、出参都有非常多重复或者冗余的字段，并且采用手动注入的方式注入
依赖，导致没法方便地做单测；

3. 没有单测也很难做单测

4. 因为整体链路很长，接口响应时间很长，高达700 - 800 ms,很影响作业效率。对于一些重操作没有并发机制；

5. 没有标准的日志、上报、监控规范，打的日志非常冗余并且混乱，容易干扰问题的定位、排查

以上问题导致新需求修改困难，容易触雷，且线上问题不容易排错

### 2.1.3 重构过程：
前期：
与产品梳理打包流程中各个市场的逻辑，找出各个市场的相同点、差异点；
与前端厘清接口设计的合理性，发现了大量已经废弃或者重复的字段；

开发阶段：
重新调整代码层次结构，让service 层的接口职责更加明确，原来的打包接口基本上是一个方法里面
从头到尾大包大榄，将所有逻辑都对到一块，根本没法复用，比如打包大体是分成校验 + 打包两
个阶段的，对于给站点操作人员作业用的逻辑这两个阶段是同步的，而我们提供给分拣机使用的接口，
这两个阶段是异步的，所以原来的代码将这写逻辑拆分成了三个接口。
打包领域最终其实就只需要提供校验、打包两个能力就行，所以在 service层我设计定义了两个接口，
让代码具有更高的复用性，包括后面有新需求需要实现一个自动打包的能力，也就是收货完成后能够做
到自动打包的能力，对于打包领域基本上代码不需要做任何变动，收货领域直接调用我们提供的两个接
口就可以实现了。

这个项目虽然技术难度上不高，但是我觉得在这个项目中，是实实在在地解决了很多的痛点。
我自己独立设计、管理好自己的排期，没有出现延期的情况下以很高的质量完成了重构；
积极学习各种知识并运用到重构过程中包括：
借鉴开源算法，实现使用DAG 图的方式来对流程进行编排、并发执行；
参考gRPC的插件功能以及Gin 框架的中间件的实现，使用基于 Go 语言的闭包和函数传递机制实现了
可注册的拦截器功能；

在项目中我积极跟各个领域协调沟通，让他们提供我们需要的接口，我积极跟pm对齐，一起梳理了业务，
弥补了我们文档这块的空白；
重构后的代码对于新同学也非常友好，能够很容易理解整个业务流程，对于新需求的开发变得很容易，而
且不再像之前一样经常触雷；
重构项目很平滑稳定地上线了，并且将接口响应时间缩减了特别的多，让线下作业效率变得更加高效了；


## 2.2 库存盘点
项目主要提供支持每日定时对站点内包裹重新扫描盘点，实时了解站内包裹积压和遗失状态，及时处理遗失件，
同时生成以下数据：last mile hub 的每日入库清单 、记录盘点清单，并支持业务在盘点作业中，更新订
单的当前站点信息及状态生成 、last mile hub 的每日盘点前 & 盘点期间出库清单、推算出历史库存件
清单，丢失件清单，生成盘点报告。

主要是一个报表类、数据统计相关的需求。

Es 和 Ck 的选型：
CK列式存储:
1. 亿行数据毫秒级响应
2. 兼容 SQL 语法，维护成本低
3. 查询和插入不支持高QPS，视集群性能在几十到几百的QPS，因此不适合一线业务直接读写，例如核心作业
流程;适合统计分析、报表监控、导出查询等操作
4. 没有删除操作，使用逻辑删除;join 性能很强
5. 多主架构，同一查询可能有数据延迟、不一致,使用final关键字保持一致
6. 适合大批量低频率插入


Redis 作用：
1.分布式锁

2.缓存
缓存的是用户查询请求，报表展示的维度主要分为两类：1是按日期维度的查询展示； 2是按region（区域）维度的查询展示，
上线后发现大多数用户在一段时间内有许多重复的查询请求，因为我们存储使用了CK，它因为基建的原因，偶尔出现不稳定的情
况，以及它的查询会占用比较多的资源，所以查询偶尔会出现比较慢的情况，所以我考虑给用户的查询增加了一个缓存，另外，
我发现线上有一个很有意思的情况，就是用户习惯在连续的两次请求里分别查询按日期维度和按region 维度的数据。所以我在
给这两个查询都增加了一个预缓存的机制，比如：用户按日期维度查询的时候，很大概率他下次就会按region 维度查询，所以
我使用go 协程对接下来的请求查询提前先做，并缓存下来。
加了缓存后，原来比较多的高达十几s的查询基本就没有再出现过了。

ClickHouse的查询缓存是一种可嵌入式的缓存机制，
可以在查询语句中使用特定的语法来启用缓存。例如，
在查询语句中添加CACHE关键字，可以将查询结果缓
存到内存中。如果相同的查询被多次执行，ClickHouse
会直接从缓存中获取结果，而不必再次执行查询，从
而提高查询的性能和吞吐量。 使用查询缓存可以提高
查询的性能和响应速度，特别是在相同的查询被多次执
行时，可以避免重复计算和查询，从而节省系统资源。

------
# 2.工作遇到的问题
## 2.1 MySQL 遇到的问题
### 2.1.1 死锁的问题
性能下降：死锁会导致事务相互等待，直到超时或者MySQL选择一个事务作为牺牲者回滚，
这样会导致事务的执行时间变长，从而影响服务的性能。
UPDATE table_name SET column1 = value1, column2 = value2, ... WHERE id=xxxx;
UPDATE table_name SET column1 = value1, column2 = value2, ... WHERE task_id=xxxxx;


MySQL死锁是指两个或多个事务相互等待对方释放资源而无法继续执行的情况。当发生死锁时，MySQL会自动选择一个事务作为死锁牺牲者进行回滚，以结束死锁。
为了排查MySQL死锁，可以执行以下步骤：
查看MySQL错误日志：在MySQL错误日志中，可以查看到死锁的详细信息，包括死锁的事务ID、死锁发生的表和行号等。可以通过查看错误日志来确定死锁发生的具体原因。
执行SHOW ENGINE INNODB STATUS命令：在MySQL命令行中执行SHOW ENGINE INNODB STATUS命令，可以查看到当前正在运行的事务、锁信息和等待情况等详细信息，通过这些信息可以判断哪些事务出现了死锁。
分析死锁日志：MySQL可以将死锁信息写入到死锁日志中，通过分析死锁日志可以找出死锁的原因和发生时间等信息。可以通过设置参数innodb_print_all_deadlocks=1来开启死锁日志记录。
使用锁监控工具：MySQL提供了一些锁监控工具，如Percona Toolkit等，可以帮助我们更方便地分析死锁问题。使用这些工具可以从多个维度查看死锁信息，包括锁等待时间、锁争用次数等。
优化查询语句和事务设计：死锁问题往往与查询语句和事务设计有关。优化查询语句和事务设计可以减少死锁的发生。例如，可以使用合适的索引、分批次操作数据、尽量避免长事务等。

### 2.1.3 查询慢
场景就是一个临期商品的数据表，里面有 type（商品类型字段），在这个字段上面有建立一个索引；
数据很离散六百万的数据，按 type 查询出来大概还有80万

MySQL 只考虑过滤出来数据的百分比，而不考虑这些数据是否分布在哪些盘片上面，所以他load 盘片多了，特别是他数据很离散的情况下，他会做大量
的回表查询并且因为数据离散的原因，增加了它随机IO 的查询，还不如直接进行全表查询。

优化： 
1.大批量插入数据的时候，尽量先排序再插入

2.optimize table xxx;
> 在MySQL中，OPTIMIZE TABLE是一种用于优化表的命令。其作用是对表进行碎片整理，从而提高查询性能和减少磁盘空间的使用。
当MySQL执行UPDATE、DELETE等操作时，会释放一些空间，但并不会自动归还给操作系统。这样，表中就会存在一些未使用的空间，称为碎片。碎片会占用磁盘空间，同时也会降低查询性能。
使用OPTIMIZE TABLE命令可以将表中的碎片整理成连续的空间，从而提高查询性能和减少磁盘空间的使用。OPTIMIZE TABLE命令会执行以下操作：
重建表：OPTIMIZE TABLE会创建一个新的表，并将原表的数据复制到新表中。在复制数据的过程中，会对数据进行整理，从而消除碎片。
优化索引：OPTIMIZE TABLE会对表中的索引进行优化，从而提高查询性能。
释放空间：OPTIMIZE TABLE会释放未使用的空间，从而减少磁盘空间的使用。
需要注意的是，OPTIMIZE TABLE命令会锁定表，因此在执行期间，其他用户无法对表进行修改。因此，在执行OPTIMIZE TABLE命令之前，需要确保没有其他用户正在使用该表。
使用OPTIMIZE TABLE命令的基本语法如下：
OPTIMIZE TABLE table_name;

3. force index = null
> 在MySQL中，FORCE INDEX是一种用于强制MySQL使用指定的索引的命令。在某些情况下，MySQL的查询优化器可能会选择不是最优的索引，或者根本不使用索引。这时，可以使用FORCE INDEX命令来强制MySQL使用指定的索引。
使用FORCE INDEX命令的基本语法如下：
SELECT * FROM table_name FORCE INDEX (index_name) WHERE condition;
其中，table_name是要查询的表名，index_name是要强制使用的索引名，condition是查询条件。
需要注意的是，使用FORCE INDEX命令可能会导致查询性能下降，因为MySQL会强制使用指定的索引，而不考虑其他可能更优的索引。因此，在使用FORCE INDEX命令之前，需要仔细评估索引的选择，确认强制使用指定的索引能够提高查询性能。
另外，MySQL也提供了另外一种命令INDEX HINT，可以指定MySQL使用某个索引，但不强制必须使用，语法如下：
SELECT * FROM table_name USE INDEX (index_name) WHEREcondition;
其中，USE INDEX命令会提示MySQL使用指定的索引，但不强制必须使用，MySQL仍然会根据查询条件和其他因素来选择最优的索引。

几十 s 级别优化到 s 级别

---------
可维护性高的代码通常具有以下特点：
1. 易读性好：代码易于阅读和理解，命名清晰、简洁明了、注释充分、结构清晰、缩进合理等。
2. 易修改性好：代码易于修改和扩展，代码的耦合度低、模块化设计、接口设计良好、代码复用度高等。
3. 可测试性好：代码易于测试和调试，代码的单元测试、集成测试、自动化测试等能够覆盖到代码的各个部分，测试结果可靠。
4. 健壮性好：代码具有强健性，能够处理各种边界情况，不易出现异常和错误情况。
5. 可维护性好：代码易于维护和修复问题，能够快速定位和修复问题，代码的修改和维护不会对其他部分产生影响。
6. 性能高效：代码的执行效率高，不会因为性能问题而影响用户体验。
7. 可扩展性好：代码易于扩展和升级，能够满足未来的需求和变化，不会影响到已有的功能和代码。
维护性高的代码能够帮助开发人员更加高效、稳定地进行开发和维护工作，也更容易被其他开发人员理解和修改。同时，可维护性高的代码也能够降低软件开发和维护的成本和风险。为了提高代码的可维护性，开发人员需要注重代码的设计、命名、注释、测试等方面，同时也需要采用合适的编码规范和设计模式等技术手段来优化代码的质量和可维护性。


代码重构是指在不改变代码外部行为的情况下，通过修改代码内部结构和实现方式，以提高代码的质量、可读性、可维护性和可扩展性的过程。代码重构的目的是为了使代码更易于理解、修改和扩展，从而提高代码的质量和可维护性。

以下是代码重构的一些常见目的：
1. 提高代码质量：通过消除代码中的重复、复杂度和不必要的依赖等问题，可以提高代码的质量和可读性。
2. 简化代码实现：通过使用更简单、更清晰的实现方式，可以使代码更易于理解和修改。
3. 提高可维护性：通过将代码分解为逻辑上独立的模块、使用设计模式、引入注释和文档等最佳实践，可以提高代码的可维护性和稳定性。
4. 改进代码性能：通过优化代码结构和实现方式，可以提高代码的性能和效率。
5. 改进代码可读性：通过使用有意义的变量和函数名、遵循编码规范、引入注释和文档等最佳实践，可以提高代码的可读性，使其更易于理解和修改。
6. 改进代码扩展性：通过模块化设计、使用设计模式等最佳实践，可以提高代码的可扩展性，使其更易于扩展和适应变化的需求。
总之，代码重构的目的是为了改善代码的质量和可维护性，使其更易于理解、修改和扩展。通过不断地进行代码重构，可以使代码保持健康和稳定，从而更好地满足业务需求和用户需求。


## 3.职业规划
1、1年内，我会先熟悉工作环境，学习公司文化并融入其中，
同时对自己的不足加以改进，学习并提升自己的专业技能，向
领导和老员工虚心请教，争取做好自己的本职工作。

2、1-2年，不断地学习和丰富自己的专业知识，通过自己的
努力成为岗位的技术能手，同时希望通过带新人，锻炼和提升
自己的管理和综合能力。

3、2-3年，通过学习和努力，在专业、综合能力都能符合公司
要求的情况下，逐渐承担一定的管理职责，并继续学习和提升自
己的大局观、沟通和团队领导能力，为公司做出更大的贡献;


## 4.微服务治理
微服务治理技术是一种用于管理和协调微服务架构中各个服务的方法。微服务治理技术的目标是确保系统的稳定性、可扩展性、可维护性和高性能。以下是一些常见的微服务治理技术：

1. 服务注册与发现：通过服务注册中心，各个微服务实例可以注册自己的信息，同时查询其他服务的信息。常见的服务注册与发现工具有Eureka、Consul和Zookeeper。

2. API网关：API网关是微服务架构中的入口点，负责请求的路由、负载均衡、认证授权和限流等功能。常见的API网关有Zuul、Kong和Spring Cloud Gateway。

3. 负载均衡：在微服务架构中，负载均衡可以分为客户端负载均衡和服务端负载均衡。客户端负载均衡通常由API网关或服务调用者实现，如Ribbon。服务端负载均衡则由服务提供者实现，如Nginx。

4. 服务熔断与降级：服务熔断是一种防止服务雪崩的机制，当某个服务出现故障时，熔断器会拦截请求，防止故障扩散。服务降级是在服务出现故障或者响应过慢时，返回一个预设的默认响应。常见的熔断与降级工具有Hystrix和Resilience4j。

5. 分布式追踪：分布式追踪用于收集和分析微服务之间的调用关系和性能数据，帮助开发者定位问题和优化性能。常见的分布式追踪工具有Zipkin、Jaeger和OpenTracing。

6. 配置中心：配置中心用于集中管理微服务的配置信息，实现配置的动态更新和版本控制。常见的配置中心有Spring Cloud Config、Apollo和Consul。

7. 容器化与编排：容器化技术（如Docker）可以简化微服务的部署和管理，而编排工具（如Kubernetes）则负责自动化部署、扩缩容、滚动更新等任务。

8. 日志管理：在微服务架构中，统一收集、存储和分析日志信息至关重要。常见的日志管理工具有ELK（Elasticsearch、Logstash、Kibana）和EFK（Elasticsearch、Fluentd、Kibana）。

9. 监控与告警：监控微服务的运行状态和性能指标，及时发现和处理问题。常见的监控与告警工具有Prometheus、Grafana和Alertmanager。

这些技术可以根据项目的需求和团队的技术栈进行选择和组合，以实现高效的微服务治理。

## 5. 你一般如何定位线上问题
1、如果线上出现了问题，我们更多的是希望由监控告警发现我们出了线上问题，而不是等到业务侧反馈。所以，我们需要对核心接口做好监控告警的功能。

2、如果是业务代码层面的监控报警，那我们应该是可以很快地定位出是哪儿的问题，毕竟告警逻辑都是我们写的嘛。如果是服务器资源/所依赖的中间件告警，那我们可能就要花点时间去排查啦。

3、不管怎么样，无论是系统告警还是是业务侧反馈系统或者接口出了问题。我们要想想在近期有没有发布过系统，如果近期发布过系统，判断能不能立马回滚到上一个版本，恢复系统平稳正常运行（在线上环境下，可用性是相当重要的）。回滚的时候要考虑接口有无依赖性，是否需要跟业务侧同步此次的回滚以及做相关的配合。

4、因为线上大多数的问题都来源于系统的变更，可能我们只是变更了很少的代码，但只要有一丝的逻辑没留意到，就真的很可能会导致出现问题，回滚很可能是最快能恢复线上正常运行的办法。

5、如果近期都没发布过系统，是系统告的警，那追踪下告警和报错日志，应该是可以很快地就能定位出问题。

6、如果不是系统告的警，是业务侧反馈出了问题，那这时候需要业务侧明确是哪个具体的功能/接口出了问题，有没有保留请求入参，有没有返回错误的信息，有何现象

7、知道了问题的现象之后，就需要根据经验排查可能是哪块出了问题了。我的经验一般是：先查存储侧有没有瓶颈(MySQL 的CPU有没有飙高，主从同步延迟是否很大，有没有慢SQL。Redis是不是内存满了，走了淘汰策略。搜索引擎有没有慢Query)，把该服务所依赖的中间件的指标看一遍，这个过程中也要去看看服务接口的QPS/RT相关的监控。如果有某项指标不对劲，那顺着写入逻辑也应该很快能看出来

8、一般到这里，大多数的问题都能查出来。可能是逻辑本身的问题，可能是请求入参导致慢查询，可能是中间件的网络抖动，可能是突发或者异常请求的问题。

9、如果都不是，回归到应用和机器本身的监控：应用GC的表现、机器本身的网络/磁盘/内存/CPU 各种的指标有没有发现异常的情况。这里可能是需要运维侧一起配合看看有没有做过改动。

10、要是还定位不出来，看能不能复现，能复现都好说，肯定是能解决的。

11、要是不能复现，只能在怀疑的地方打上详细的日志再好好观察（问题定位不出来，很多时候就是日志不够详细，而日志在正常情况下也不应该打太多）

## 6.什么是幂等和去重
面试官：要不你来讲讲你最近在看的点呗？可以拉出来一起讨论下

候选者：最近在看「去重」和「幂等」相关的内容

面试官：那你就先来聊聊你对「去重」和「幂等」的理解吧

候选者：我认为「幂等」和「去重」它们很像，我也说不出他们之间的严格区别

候选者：我说下我个人的理解，我也不知道对不对

候选者：「去重」是对请求或者消息在「一定时间内」进行去重「N次」

候选者：「幂等」则是保证请求或消息在「任意时间内」进行处理，都需要保证它的结果是一致的

候选者：不论是「去重」还是「幂等」，都需要对有一个「唯一 Key」，并且有地方对唯一Key进行「存储」

候选者：以项目举例，我维护的「消息管理平台」是有「去重」的功能的：「5分钟相同内容消息去重」「1小时内模板去重」「一天内渠道达到N次阈值去重」…

候选者：再次强调下「幂等」和「去重」的本质：「唯一Key」+「存储」

面试官：那你是怎么做的呢

候选者：不同的业务场景，唯一Key是不一样的，由业务决定

候选者：存储选择挺多的，比如「本地缓存」/「Redis」/「MySQL」/「HBase」等等，具体选取什么，也跟业务有关

候选者：比如说，在「消息管理平台」这个场景下，我存储选择的「Redis」（读写性能优越），Redis也有「过期时间」方便解决「一定时间内」的问题

候选者：而唯一Key，自然就是根据不同的业务构建不同的。

候选者：比如说「5分钟相同内容消息去重」，我直接MD5请求参数作为唯一Key。「1小时模板去重」则是「模板ID+userId」作为唯一Key，「一天内渠道去重」则是「渠道ID+userId」作为唯一Key…

面试官：既然提到了「去重」了，你听过布隆过滤器吗？

候选者：自然是知道的啦

面试官：来讲讲布隆过滤器吧，你为什么不用呢？

候选者：布隆过滤器的底层数据结构可以理解为bitmap，bitmap也可以简单理解为是一个数组，元素只存储0和1，所以它占用的空间相对较小

候选者：当一个元素要存入bitmap时，其实是要去看存储到bitmap的哪个位置，这时一般用的就是哈希算法，存进去的位置标记为1

候选者：标记为1的位置表示存在，标记为0的位置标示不存在

候选者：布隆过滤器是可以以较低的空间占用来判断元素是否存在进而用于去重，但是它也有对应的缺点

候选者：只要使用哈希算法离不开「哈希冲突」，导致有存在「误判」的情况

候选者：在布隆过滤器中，如果元素判定为存在，那该元素「未必」真实存在。如果元素判定为不存在，那就肯定是不存在

候选者：这应该不用我多解释了吧？（结合「哈希算法」和「标记为1的位置表示存在，标记为0的位置标示不存在」这两者就能得出上面结论）

候选者：布隆过滤器也不能「删除」元素（也是哈希算法的局限性，在布隆过滤器中是不能准确定位一个元素的）

候选者：如果要用的话，布隆过滤器的实现可以直接上Guava已经实现好的，不过这个是单机的

候选者：而分布式下的布隆过滤器，一般现在会用Redis，但也不是没个公司都会部署布隆过滤器的Redis版（还是有局限，像我以前公司就没有）

候选者：所以，目前我负责的项目都是没有用布隆过滤器的（：

候选者：如果「去重」开销比较大，可以考虑建立「多层过滤」的逻辑

候选者：比如，先看看『本地缓存』能不能过滤一部分，剩下「强校验」交由『远程存储』（常见的Redis或者DB）进行二次过滤

面试官：嗯，那我就想起你上一次回答Kafka的时候了

面试官：当时你说在处理订单时实现了at least one + 幂等

面试官：幂等处理时：前置过滤使用的是Redis，强一致校验时使用的是DB唯一索引，也是为了提高性能，对吧？

面试官：唯一Key 好像就是 「订单编号 + 订单状态」

候选者：面试官你记性真的好！

候选者：一般我们需要对数据强一致性校验，就直接上MySQL（DB），毕竟有事务的支持

候选者：「本地缓存」如果业务适合，那可以作为一个「前置」判断

候选者：Redis高性能读写，前置判断和后置均可（：

候选者：而HBase则一般用于庞大数据量的场景下（Redis内存太贵，DB不够灵活也不适合单表存大量数据）

候选者：至于幂等，一般的存储还是「Redis」和「数据库」

候选者：最最最最常见的就是数据库「唯一索引」来实现幂等（我所负责的好几个项目都是用这个）

候选者：构建「唯一Key」是业务相关的事了（：一般是用自己的业务ID进行拼接，生成一个”有意义”的唯一Key

候选者：当然，也有用「Redis」和「MySQL」实现分布式锁来实现幂等的（：

候选者：但Redis分布式锁是不能完全保证安全的，而MySQL实现分布式锁（乐观锁和悲观锁还是看业务吧，我是没用到过的）

候选者：网上有很多实现「幂等」的方案，本质上都是围绕着「存储」和「唯一Key」做了些变种，然后取了个名字…

候选者：总的来说，换汤不换药（：

## 7. DDD
### 7.1 实操
大概以下几点：
1. 通过公共平台大概梳理出系统之间的调用关系（一般中等以上公司都具备 RPC 和 HTTP 调用关系，无脑的挨个系统查询即可），画出来的可能会很乱，也可能会比较清晰，但这就是现状。 
2. 分配组员每个人认领几个项目，来梳理项目维度关系，这些关系包括：对外接口、交互、用例、MQ 等的详细说明。个别核心系统可以画出内部实体或者聚合根。 
3. 小组开会，挨个 review 每个系统的业务概念，达到组内统一语言。 
4. 根据以上资料，即可看出哪些不合理的调用关系（比如循环调用、不规范的调用等），甚至不合理的分层。 
5. 根据主线业务自顶向下细分领域，以及限界上下文。此过程可能会颠覆之前的系统划分。 
6. 根据业务复杂性，指定领域模型，选择贫血或者充血模型。团队内部最好实行统一习惯，以免出现交接成本过大。 
7. 分工进行开发，并设置 deadline，注意，不要单一的设置一个 deadline，要设置中间 check 时间，比如 dealline 是 1 月 20 日，还要设置两个 check 时间，分别沟通代码风格及边界职责，以免 deadline 时延期。

### 7.2 DDD介绍
DDD 全程是 Domain-Driven Design，中文叫领域驱动设计，是一套应对复杂软件系统分析和设计的面向对象建模方法论。

同时期，随着互联网的兴起，Rod Johnson 这大哥以轻量级极简风格的 Spring Cloud 抢占了所有风头，虽然 Spring 推崇的失血模式并非 OOP 的皇家血统，但是谁用关心这些呢？毕竟简化开发的成本才是硬道理。

就在我们用这张口闭口 Spring 的时候，我们意识到了一个严重的问题，我们应对复杂业务场景的时候，Spring 似乎并不能给出更合理的解决方案，于是分而治之的思想下应生了微服务，一改以往单体应用为多个子应用，一下子让人眼前一亮，于是我们没日没夜地拆分服务，加之微服务提供的注册中心、熔断、限流等解决方案，我们用得不亦乐乎。

人们在踩过诸多拆分服务的坑（拆分过细导致服务爆炸、拆分不合理导致频分重构等）之后，开始死锁原因了，到底有没有一种方法论可以指导人们更加合理地拆分服务呢？众里寻他千百度，DDD 却在灯火阑珊处，有了 DDD 的指导，加之微服务的事件，才是完美的架构。
背景中我们说到，有 DDD 的指导，加之微服务的事件，才是完美的架构，这里就详细说下它们的关系。

系统的复杂度越来越来高是必然趋势，原因可能来自自身业务的演进，也有可能是技术的创新，然而一个人和团队对复杂性的认知是有极限的，就像一个服务器的性能极限一样，解决的办法只有分而治之，将大问题拆解为小问题，最终突破这种极限。微服务在这方面都给出来了理论指导和最佳实践，诸如注册中心、熔断、限流等解决方案，但微服务并没有对“应对复杂业务场景”这个问题给出合理的解决方案，这是因为微服务的侧重点是治理，而不是分。

我们都知道，架构一个系统的时候，应该从以下几方面考虑：

功能维度
质量维度（包括性能和可用性）
工程维度
微服务在第二个做得很好，但第一个维度和第三个维度做的不够。这就给 DDD 了一个“可乘之机”，DDD 给出了微服务在功能划分上没有给出的很好指导这个缺陷。所以说它们在面对复杂问题和构建系统时是一种互补的关系。

从架构角度看，微服务中的服务所关注的范围，正是 DDD 所推崇的六边形架构中的领域层，和整洁架构中的 entity 和 use cases 层。

知道了 DDD 与微服务还不够，我们还需要知道他们是怎么协作的。

一个系统（或者一个公司）的业务范围和在这个范围里进行的活动，被称之为领域，领域是现实生活中面对的问题域，和软件系统无关，领域可以划分为子域，比如电商领域可以划分为商品子域、订单子域、发票子域、库存子域 等，在不同子域里，不同概念会有不同的含义，所以我们在建模的时候必须要有一个明确的边界，这个边界在 DDD 中被称之为限界上下文，它是系统架构内部的一个边界

所以复杂系统划分的第一要素就是划分系统内部架构边界，也就是划分上下文，以及明确之间的关系，这对应之前说的第一维度（功能维度），这就是 DDD 的用武之处。其次，我们才考虑基于非功能的维度如何划分，这才是微服务发挥优势的地方。

我们可以在一个进程内部署单体应用，也可以通过远程调用来完成功能调用，这就是目前的微服务方式，更多的时候我们是两种方式的混合，比如 A 和 B 在一个部署单元内，C 单独部署，这是因为 C 非常重要，或并发量比较大，或需求变更比较频繁，这时候 C 独立部署有几个好处：

C 独立部署资源：资源更合理的倾斜，独立扩容缩容。
弹力服务：重试、熔断、降级等，已达到故障隔离。
技术栈独立：C 可以使用其他语言编写，更合适个性化团队技术栈。
团队独立：可以由不同团队负责。
架构是可以演进的，所以拆分需要考虑架构的阶段，早期更注重业务逻辑边界，后期需要考虑更多方面，比如数据量、复杂性等，但即使有这个方针，也常会见仁见智，没有人能一下子将边界定义正确，其实这里根本就没有明确的对错。

即使边界定义的不太合适，通过聚合根可以保障我们能够演进出更合适的上下文，在上下文内部通过实体和值对象来对领域概念进行建模，一组实体和值对象归属于一个聚合根。

按照 DDD 的约束要求：

第一，聚合根来保证内部实体规则的正确性和数据一致性；
第二，外部对象只能通过 id 来引用聚合根，不能引用聚合根内部的实体；
第三，聚合根之间不能共享一个数据库事务，他们之间的数据一致性需要通过最终一致性来保证。
有了聚合根，再基于这些约束，未来可以根据需要，把聚合根升级为上下文，甚至拆分成微服务，都是比较容易的。

### 7.3 概念
**领域**
映射概念：切分的服务。

领域就是范围。范围的重点是边界。领域的核心思想是将问题逐级细分来减低业务和系统的复杂度，这也是 DDD 讨论的核心。

**子域**
映射概念：子服务。

领域可以进一步划分成子领域，即子域。这是处理高度复杂领域的设计思想，它试图分离技术实现的复杂性。这个拆分的里面在很多架构里都有，比如 C4。

**核心域**
映射概念：核心服务。

在领域划分过程中，会不断划分子域，子域按重要程度会被划分成三类：核心域、通用域、支撑域。

决定产品核心竞争力的子域就是核心域，没有太多个性化诉求。

桃树的例子，有根、茎、叶、花、果、种子等六个子域，不同人理解的核心域不同，比如在果园里，核心域就是果是核心域，在公园里，核心域则是花。有时为了核心域的营养供应，还会剪掉通用域和支撑域（茎、叶等）。

**通用域**
映射概念：中间件服务或第三方服务。

被多个子域使用的通用功能就是通用域，没有太多企业特征，比如权限认证。

**支撑域**
映射概念：企业公共服务。

对于功能来讲是必须存在的，但它不对产品核心竞争力产生影响，也不包含通用功能，有企业特征，不具有通用性，比如数据代码类的数字字典系统。

**统一语言**
映射概念：统一概念。

定义上下文的含义。它的价值是可以解决交流障碍，不管你是 RD、PM、QA 等什么角色，让每个团队使用统一的语言（概念）来交流，甚至可读性更好的代码。

通用语言包含属于和用例场景，并且能直接反应在代码中。

可以在事件风暴（开会）中来统一语言，甚至是中英文的映射、业务与代码模型的映射等。可以使用一个表格来记录。

**限界上下文**
映射概念：服务职责划分的边界。

定义上下文的边界。领域模型存在边界之内。对于同一个概念，不同上下文会有不同的理解，比如商品，在销售阶段叫商品，在运输阶段就叫货品。


理论上，限界上下文的边界就是微服务的边界，因此，理解限界上下文在设计中非常重要。

**聚合**
映射概念：包。

聚合概念类似于你理解的包的概念，每个包里包含一类实体或者行为，它有助于分散系统复杂性，也是一种高层次的抽象，可以简化对领域模型的理解。

拆分的实体不能都放在一个服务里，这就涉及到了拆分，那么有拆分就有聚合。聚合是为了保证领域内对象之间的一致性问题。

在定义聚合的时候，应该遵守不变形约束法则：

聚合边界内必须具有哪些信息，如果没有这些信息就不能称为一个有效的聚合；
聚合内的某些对象的状态必须满足某个业务规则：
一个聚合只有一个聚合根，聚合根是可以独立存在的，聚合中其他实体或值对象依赖与聚合根。
只有聚合根才能被外部访问到，聚合根维护聚合的内部一致性。

**聚合根**
映射概念：包。

一个上下文内可能包含多个聚合，每个聚合都有一个根实体，叫做聚合根，一个聚合只有一个聚合根。

**实体**
映射概念：Domain 或 entity。

《领域驱动设计模式、原理与实践》一书中讲到，实体是具有身份和连贯性的领域概念，可以看出，实体其实也是一种特殊的领域，这里我们需要注意两点：唯一标示（身份）、连续性。两者缺一不可。

你可以想象，文章可以是实体，作者也可以是，因为它们有 id 作为唯一标示。

**值对象**
映射概念：Domain 或 entity。

为了更好地展示领域模型之间的关系，制定的一个对象，本质上也是一种实体，但相对实体而言，它没有状态和身份标识，它存在的目的就是为了表示一个值，通常使用值对象来传达数量的形式来表示。

比如 money，让它具有 id 显然是不合理的，你也不可能通过 id 查询一个 money。

定义值对象要依照具体场景的区分来看，你甚至可以把 Article 中的 Author 当成一个值对象，但一定要清楚，Author 独立存在的时候是实体，或者要拿 Author 做复杂的业务逻辑，那么 Author 也会升级为聚合根。

### 7.4 领域模型
**失血模型**
Domain Object 只有属性的 getter/setter 方法的纯数据类，所有的业务逻辑完全由 business object 来完成。

**贫血模型**
简单来说，就是 Domain Object 包含了不依赖于持久化的领域逻辑，而那些依赖持久化的领域逻辑被分离到 Service 层。
注意这个模式不在 Domain 层里依赖 DAO。持久化的工作还需要在 DAO 或者 Service 中进行。
这样做的优缺点
优点：各层单向依赖，结构清晰。
缺点：
Domain Object 的部分比较紧密依赖的持久化 Domain Logic 被分离到 Service 层，显得不够 OO
Service 层过于厚重

**充血模型**
充血模型和第二种模型差不多，区别在于业务逻辑划分，将绝大多数业务逻辑放到 Domain 中，Service 是很薄的一层，封装少量业务逻辑，并且不和 DAO 打交道：
Service (事务封装) —> Domain Object <—> DAO

所有业务逻辑都在 Domain 中，事务管理也在 Item 中实现。这样做的优缺点如下。
优点：

更加符合 OO 的原则；
Service 层很薄，只充当 Facade 的角色，不和 DAO 打交道。
缺点：
DAO 和 Domain Object 形成了双向依赖，复杂的双向依赖会导致很多潜在的问题。
如何划分 Service 层逻辑和 Domain 层逻辑是非常含混的，在实际项目中，由于设计和开发人员的水平差异，可能 导致整个结构的混乱无序。

**胀血模型**
基于充血模型的第三个缺点，有同学提出，干脆取消 Service 层，只剩下 Domain Object 和 DAO 两层，在 Domain Object 的 Domain Logic 上面封装事务。
Domain Object (事务封装，业务逻辑) <—> DAO
似乎 Ruby on rails 就是这种模型，它甚至把 Domain Object 和 DAO 都合并了。
这样做的优缺点：
简化了分层
也算符合 OO
该模型缺点：
很多不是 Domain Logic 的 Service 逻辑也被强行放入 Domain Object ，引起了 Domain Object 模型的不稳定；
Domain Object 暴露给 Web 层过多的信息，可能引起意想不到的副作用。

---------
## 网络
> [计算机网络](https://stubbornwdb.github.io/MyNotes/#/notes/计算机网络3.md) 

## 操作系统
> [计算机操作系统](https://stubbornwdb.github.io/MyNotes/#/notes/计算机操作系统.md) </br>
> [Linux](https://stubbornwdb.github.io/MyNotes/#/notes/Linux.md)

## 数据库
> [MySQL](https://stubbornwdb.github.io/MyNotes/#/notes/MySQL.md) </br>
> [Redis面经](https://stubbornwdb.github.io/MyNotes/#/mynotes/redis/RedisQuestion.md)

## 消息队列
> [消息队列](https://stubbornwdb.github.io/MyNotes/#/notes/消息队列.md)

## Go
> [Go](https://stubbornwdb.github.io/MyNotes/#/mynotes/Go/go-interview.md)

## 系统设计
> [系统设计](https://stubbornwdb.github.io/MyNotes/#/mynotes/SystemDesign/SystemDesign.md)
