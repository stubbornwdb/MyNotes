# 1.自我介绍
你好，很高兴有机会参加你们公司的面试。我是21年毕业的，大学学的专业就是计算机科学与技术，
毕业后入职xxx公司，主要是在xxx团队担任后端开发的角色，先后参与过多个项目设计、开发工作。
日常工作的话主要是使用 go 语言进行开发，涉及技术栈包括 mysql 、 saturn 、kafka、 
redis 等。


你的话我建议你可以找一下：
1，抗压能力：在多个并发高优需求下，能够很高质量地有序完成所有需求，并做好个人管理
2，学习能力：在项目不断发展地过程中，你还不断地去补相关知识，以解决遇到的问题（比
如你是不是没有提，在搞python proxy时，你的header处理那部分？就返回的body一大
就导致报错的那个）
3，个人的主动性

# 2.项目介绍
## 2.1 出库模块
### 2.1.1 模块的功能
介绍：和国内所有快递业务一样，运单到达网点后，需要先进行收货，然后根据运单的数据，判断货物流向。
站内操作人员会先进行站内收货动作，收完货后，会对订单进行分拣打包。 打包时，操作人员扫描订单号后，
传给后端进行代码逻辑判断，判断是否是同一个转运类型和转运目的地。如果相同，则可以加入到同一个转运
包中。打包好后就进行交接给下游（干线运输、派送或交接给第三方物流商）。当然了，也涉及逆向流程，也
就是发起回退的流程，也同样是类似的操作，站点收货、交接。所以站内这个团队被划分为入库、出库、操作
作业单、容器、分拣机几个领域。我主要是负责打包这个模块的业务。打包模块涉及交互的领域非常多，所以
我们打包的调用链路在业务本身上就是很长的，我们核心作业接口面向的使用方主要是两个：站内操作人员以
及分拣机。

主要工作：我在这边做的最核心的一个项目就是进行了打包模块的重构。
1. 在mentor的帮助下设计并开发了一个基于DAG图的编排框架，用于将打包的各个流程进行编排，通过go
协程来异步执行各个没有依赖的流程；
2. 与产品共同厘清了打包流程中不同市场的校验逻辑，并整理出了完整的文档；
3. 重构后的代码简单易读，可维护性很高，并且增加了完整的单元测试，保证程序的可靠性；
4. 设计并开发除了基于日志的对账以及告警功能，在上线前通过对账的方式保证重构逻辑的正确性，通过一
段时间的验证后顺利完成了新代码的灰度以及切流；

代码大体逻辑是：根据调用方传入的订单号、查询运单信息、调用其他
第三方（路由、计费、收货、派送等各个域进行相关的校验）、调用容器服务将打包信息落库、查询并组装渲
染数据返回给调用方。

### 2.1.2 进行重构的原因是什么
1. 代码逻辑很混乱，可读性很差，非常难以维护。主要体现在：
- 代码中的重复的地方很多，相同功能有不同的实现，没有通用性、代码复杂度高，特别是判断转运包类型的逻辑，使
用了非常多的if else嵌套，很难维护

使用了策略模式对这部分代码重构，定义了一个 TOStrategy 的接口，它主要包括两个方法， isMatch()  process() 两个方法，
isMatch 是各个类型的TO 的具体判断逻辑， process 是对应需要执行的装填数据、以及校验的逻辑。
> 策略模式是一种行为设计模式，它定义了一系列算法，并将每个算法封装在一个具有共同接口的类中，使得它们可以相互替换。策略模式让算法独立于使用它的

另外，还使用了一个责任链的模式来处理各个市场不同的校验内容。
主要是定义一个校验器的接口，以及一个执行链，校验器主要包括： Name() 用于获取校验器名称，和 Validate() 用于执行校验逻辑 两个方法，在
执行链中，通过apollo 配置了需要执行的校验器 （一个校验器接口的slice, 根据apollo配置进行append），最后通过遍历执行责任链上面各个校验器的校验方法
> 责任链模式（Chain of Responsibility）也是一种行为设计模式，它是一种处理请求的模式，它让多个处理器都有机会处理该请求，直到其中某个处理成功为止。责任链模式把多个处理器串成链，然后让请求在链上传递

- 滥用指针，打包的流程依赖订单这个实体数据，代码采用指针的方式进行整个链路的传递，导致这个数据中途被改
了都无法发现；
- 接口设计不合理，接口是面向SQL 编程的，入参、出参都有非常多重复或者冗余的字段，并且采用手动注入的方式注入
依赖，导致没法方便地做单测；

3. 没有单测也很难做单测

4. 因为整体链路很长，接口响应时间很长，高达700 - 800 ms,很影响作业效率。对于一些重操作没有并发机制；

5. 没有标准的日志、上报、监控规范，打的日志非常冗余并且混乱，容易干扰问题的定位、排查

以上问题导致新需求修改困难，容易触雷，且线上问题不容易排错

### 2.1.3 重构过程：
前期：
与产品梳理打包流程中各个市场的逻辑，找出各个市场的相同点、差异点；
与前端厘清接口设计的合理性，发现了大量已经废弃或者重复的字段；

开发阶段：
重新调整代码层次结构，让service 层的接口职责更加明确，原来的打包接口基本上是一个方法里面
从头到尾大包大榄，将所有逻辑都对到一块，根本没法复用，比如打包大体是分成校验 + 打包两
个阶段的，对于给站点操作人员作业用的逻辑这两个阶段是同步的，而我们提供给分拣机使用的接口，
这两个阶段是异步的，所以原来的代码将这写逻辑拆分成了三个接口。
打包领域最终其实就只需要提供校验、打包两个能力就行，所以在 service层我设计定义了两个接口，
让代码具有更高的复用性，包括后面有新需求需要实现一个自动打包的能力，也就是收货完成后能够做
到自动打包的能力，对于打包领域基本上代码不需要做任何变动，收货领域直接调用我们提供的两个接
口就可以实现了。

这个项目虽然技术难度上不高，但是我觉得在这个项目中，是实实在在地解决了很多的痛点。
我自己独立设计、管理好自己的排期，没有出现延期的情况下以很高的质量完成了重构；
积极学习各种知识并运用到重构过程中包括：
借鉴开源算法，实现使用DAG 图的方式来对流程进行编排、并发执行；
参考gRPC的插件功能以及Gin 框架的中间件的实现，使用基于 Go 语言的闭包和函数传递机制实现了
可注册的拦截器功能；

在项目中我积极跟各个领域协调沟通，让他们提供我们需要的接口，我积极跟pm对齐，一起梳理了业务，
弥补了我们文档这块的空白；
重构后的代码对于新同学也非常友好，能够很容易理解整个业务流程，对于新需求的开发变得很容易，而
且不再像之前一样经常触雷；
重构项目很平滑稳定地上线了，并且将接口响应时间缩减了特别的多，让线下作业效率变得更加高效了；


## 2.2 库存盘点
项目主要提供支持每日定时对站点内包裹重新扫描盘点，实时了解站内包裹积压和遗失状态，及时处理遗失件，
同时生成以下数据：last mile hub 的每日入库清单 、记录盘点清单，并支持业务在盘点作业中，更新订
单的当前站点信息及状态生成 、last mile hub 的每日盘点前 & 盘点期间出库清单、推算出历史库存件
清单，丢失件清单，生成盘点报告。

主要是一个报表类、数据统计相关的需求。

Es 和 Ck 的选型：
CK列式存储:
1. 亿行数据毫秒级响应
2. 兼容 SQL 语法，维护成本低
3. 查询和插入不支持高QPS，视集群性能在几十到几百的QPS，因此不适合一线业务直接读写，例如核心作业
流程;适合统计分析、报表监控、导出查询等操作
4. 没有删除操作，使用逻辑删除;join 性能很强
5. 多主架构，同一查询可能有数据延迟、不一致,使用final关键字保持一致
6. 适合大批量低频率插入


Redis 作用：
1.分布式锁

2.缓存
缓存的是用户查询请求，报表展示的维度主要分为两类：1是按日期维度的查询展示； 2是按region（区域）维度的查询展示，
上线后发现大多数用户在一段时间内有许多重复的查询请求，因为我们存储使用了CK，它因为基建的原因，偶尔出现不稳定的情
况，以及它的查询会占用比较多的资源，所以查询偶尔会出现比较慢的情况，所以我考虑给用户的查询增加了一个缓存，另外，
我发现线上有一个很有意思的情况，就是用户习惯在连续的两次请求里分别查询按日期维度和按region 维度的数据。所以我在
给这两个查询都增加了一个预缓存的机制，比如：用户按日期维度查询的时候，很大概率他下次就会按region 维度查询，所以
我使用go 协程对接下来的请求查询提前先做，并缓存下来。
加了缓存后，原来比较多的高达十几s的查询基本就没有再出现过了。

ClickHouse的查询缓存是一种可嵌入式的缓存机制，
可以在查询语句中使用特定的语法来启用缓存。例如，
在查询语句中添加CACHE关键字，可以将查询结果缓
存到内存中。如果相同的查询被多次执行，ClickHouse
会直接从缓存中获取结果，而不必再次执行查询，从
而提高查询的性能和吞吐量。 使用查询缓存可以提高
查询的性能和响应速度，特别是在相同的查询被多次执
行时，可以避免重复计算和查询，从而节省系统资源。

------
# 2.工作遇到的问题
## 2.1 MySQL 遇到的问题
### 2.1.1 死锁的问题
性能下降：死锁会导致事务相互等待，直到超时或者MySQL选择一个事务作为牺牲者回滚，
这样会导致事务的执行时间变长，从而影响服务的性能。
UPDATE table_name SET column1 = value1, column2 = value2, ... WHERE id=xxxx;
UPDATE table_name SET column1 = value1, column2 = value2, ... WHERE task_id=xxxxx;


MySQL死锁是指两个或多个事务相互等待对方释放资源而无法继续执行的情况。当发生死锁时，MySQL会自动选择一个事务作为死锁牺牲者进行回滚，以结束死锁。
为了排查MySQL死锁，可以执行以下步骤：
查看MySQL错误日志：在MySQL错误日志中，可以查看到死锁的详细信息，包括死锁的事务ID、死锁发生的表和行号等。可以通过查看错误日志来确定死锁发生的具体原因。
执行SHOW ENGINE INNODB STATUS命令：在MySQL命令行中执行SHOW ENGINE INNODB STATUS命令，可以查看到当前正在运行的事务、锁信息和等待情况等详细信息，通过这些信息可以判断哪些事务出现了死锁。
分析死锁日志：MySQL可以将死锁信息写入到死锁日志中，通过分析死锁日志可以找出死锁的原因和发生时间等信息。可以通过设置参数innodb_print_all_deadlocks=1来开启死锁日志记录。
使用锁监控工具：MySQL提供了一些锁监控工具，如Percona Toolkit等，可以帮助我们更方便地分析死锁问题。使用这些工具可以从多个维度查看死锁信息，包括锁等待时间、锁争用次数等。
优化查询语句和事务设计：死锁问题往往与查询语句和事务设计有关。优化查询语句和事务设计可以减少死锁的发生。例如，可以使用合适的索引、分批次操作数据、尽量避免长事务等。

### 2.1.3 查询慢
场景就是一个临期商品的数据表，里面有 type（商品类型字段），在这个字段上面有建立一个索引；
数据很离散六百万的数据，按 type 查询出来大概还有80万

MySQL 只考虑过滤出来数据的百分比，而不考虑这些数据是否分布在哪些盘片上面，所以他load 盘片多了，特别是他数据很离散的情况下，他会做大量
的回表查询并且因为数据离散的原因，增加了它随机IO 的查询，还不如直接进行全表查询。

优化： 
1.大批量插入数据的时候，尽量先排序再插入

2.optimize table xxx;
> 在MySQL中，OPTIMIZE TABLE是一种用于优化表的命令。其作用是对表进行碎片整理，从而提高查询性能和减少磁盘空间的使用。
当MySQL执行UPDATE、DELETE等操作时，会释放一些空间，但并不会自动归还给操作系统。这样，表中就会存在一些未使用的空间，称为碎片。碎片会占用磁盘空间，同时也会降低查询性能。
使用OPTIMIZE TABLE命令可以将表中的碎片整理成连续的空间，从而提高查询性能和减少磁盘空间的使用。OPTIMIZE TABLE命令会执行以下操作：
重建表：OPTIMIZE TABLE会创建一个新的表，并将原表的数据复制到新表中。在复制数据的过程中，会对数据进行整理，从而消除碎片。
优化索引：OPTIMIZE TABLE会对表中的索引进行优化，从而提高查询性能。
释放空间：OPTIMIZE TABLE会释放未使用的空间，从而减少磁盘空间的使用。
需要注意的是，OPTIMIZE TABLE命令会锁定表，因此在执行期间，其他用户无法对表进行修改。因此，在执行OPTIMIZE TABLE命令之前，需要确保没有其他用户正在使用该表。
使用OPTIMIZE TABLE命令的基本语法如下：
OPTIMIZE TABLE table_name;

3. force index = null
> 在MySQL中，FORCE INDEX是一种用于强制MySQL使用指定的索引的命令。在某些情况下，MySQL的查询优化器可能会选择不是最优的索引，或者根本不使用索引。这时，可以使用FORCE INDEX命令来强制MySQL使用指定的索引。
使用FORCE INDEX命令的基本语法如下：
SELECT * FROM table_name FORCE INDEX (index_name) WHERE condition;
其中，table_name是要查询的表名，index_name是要强制使用的索引名，condition是查询条件。
需要注意的是，使用FORCE INDEX命令可能会导致查询性能下降，因为MySQL会强制使用指定的索引，而不考虑其他可能更优的索引。因此，在使用FORCE INDEX命令之前，需要仔细评估索引的选择，确认强制使用指定的索引能够提高查询性能。
另外，MySQL也提供了另外一种命令INDEX HINT，可以指定MySQL使用某个索引，但不强制必须使用，语法如下：
SELECT * FROM table_name USE INDEX (index_name) WHEREcondition;
其中，USE INDEX命令会提示MySQL使用指定的索引，但不强制必须使用，MySQL仍然会根据查询条件和其他因素来选择最优的索引。

几十 s 级别优化到 s 级别

---------
可维护性高的代码通常具有以下特点：
1. 易读性好：代码易于阅读和理解，命名清晰、简洁明了、注释充分、结构清晰、缩进合理等。
2. 易修改性好：代码易于修改和扩展，代码的耦合度低、模块化设计、接口设计良好、代码复用度高等。
3. 可测试性好：代码易于测试和调试，代码的单元测试、集成测试、自动化测试等能够覆盖到代码的各个部分，测试结果可靠。
4. 健壮性好：代码具有强健性，能够处理各种边界情况，不易出现异常和错误情况。
5. 可维护性好：代码易于维护和修复问题，能够快速定位和修复问题，代码的修改和维护不会对其他部分产生影响。
6. 性能高效：代码的执行效率高，不会因为性能问题而影响用户体验。
7. 可扩展性好：代码易于扩展和升级，能够满足未来的需求和变化，不会影响到已有的功能和代码。
维护性高的代码能够帮助开发人员更加高效、稳定地进行开发和维护工作，也更容易被其他开发人员理解和修改。同时，可维护性高的代码也能够降低软件开发和维护的成本和风险。为了提高代码的可维护性，开发人员需要注重代码的设计、命名、注释、测试等方面，同时也需要采用合适的编码规范和设计模式等技术手段来优化代码的质量和可维护性。


代码重构是指在不改变代码外部行为的情况下，通过修改代码内部结构和实现方式，以提高代码的质量、可读性、可维护性和可扩展性的过程。代码重构的目的是为了使代码更易于理解、修改和扩展，从而提高代码的质量和可维护性。

以下是代码重构的一些常见目的：
1. 提高代码质量：通过消除代码中的重复、复杂度和不必要的依赖等问题，可以提高代码的质量和可读性。
2. 简化代码实现：通过使用更简单、更清晰的实现方式，可以使代码更易于理解和修改。
3. 提高可维护性：通过将代码分解为逻辑上独立的模块、使用设计模式、引入注释和文档等最佳实践，可以提高代码的可维护性和稳定性。
4. 改进代码性能：通过优化代码结构和实现方式，可以提高代码的性能和效率。
5. 改进代码可读性：通过使用有意义的变量和函数名、遵循编码规范、引入注释和文档等最佳实践，可以提高代码的可读性，使其更易于理解和修改。
6. 改进代码扩展性：通过模块化设计、使用设计模式等最佳实践，可以提高代码的可扩展性，使其更易于扩展和适应变化的需求。
总之，代码重构的目的是为了改善代码的质量和可维护性，使其更易于理解、修改和扩展。通过不断地进行代码重构，可以使代码保持健康和稳定，从而更好地满足业务需求和用户需求。


## 3.职业规划
1、1年内，我会先熟悉工作环境，学习公司文化并融入其中，
同时对自己的不足加以改进，学习并提升自己的专业技能，向
领导和老员工虚心请教，争取做好自己的本职工作。

2、1-2年，不断地学习和丰富自己的专业知识，通过自己的
努力成为岗位的技术能手，同时希望通过带新人，锻炼和提升
自己的管理和综合能力。

3、2-3年，通过学习和努力，在专业、综合能力都能符合公司
要求的情况下，逐渐承担一定的管理职责，并继续学习和提升自
己的大局观、沟通和团队领导能力，为公司做出更大的贡献;


## 4.微服务治理
微服务治理技术是一种用于管理和协调微服务架构中各个服务的方法。微服务治理技术的目标是确保系统的稳定性、可扩展性、可维护性和高性能。以下是一些常见的微服务治理技术：

1. 服务注册与发现：通过服务注册中心，各个微服务实例可以注册自己的信息，同时查询其他服务的信息。常见的服务注册与发现工具有Eureka、Consul和Zookeeper。

2. API网关：API网关是微服务架构中的入口点，负责请求的路由、负载均衡、认证授权和限流等功能。常见的API网关有Zuul、Kong和Spring Cloud Gateway。

3. 负载均衡：在微服务架构中，负载均衡可以分为客户端负载均衡和服务端负载均衡。客户端负载均衡通常由API网关或服务调用者实现，如Ribbon。服务端负载均衡则由服务提供者实现，如Nginx。

4. 服务熔断与降级：服务熔断是一种防止服务雪崩的机制，当某个服务出现故障时，熔断器会拦截请求，防止故障扩散。服务降级是在服务出现故障或者响应过慢时，返回一个预设的默认响应。常见的熔断与降级工具有Hystrix和Resilience4j。

5. 分布式追踪：分布式追踪用于收集和分析微服务之间的调用关系和性能数据，帮助开发者定位问题和优化性能。常见的分布式追踪工具有Zipkin、Jaeger和OpenTracing。

6. 配置中心：配置中心用于集中管理微服务的配置信息，实现配置的动态更新和版本控制。常见的配置中心有Spring Cloud Config、Apollo和Consul。

7. 容器化与编排：容器化技术（如Docker）可以简化微服务的部署和管理，而编排工具（如Kubernetes）则负责自动化部署、扩缩容、滚动更新等任务。

8. 日志管理：在微服务架构中，统一收集、存储和分析日志信息至关重要。常见的日志管理工具有ELK（Elasticsearch、Logstash、Kibana）和EFK（Elasticsearch、Fluentd、Kibana）。

9. 监控与告警：监控微服务的运行状态和性能指标，及时发现和处理问题。常见的监控与告警工具有Prometheus、Grafana和Alertmanager。

这些技术可以根据项目的需求和团队的技术栈进行选择和组合，以实现高效的微服务治理。

## 5. 你一般如何定位线上问题
1、如果线上出现了问题，我们更多的是希望由监控告警发现我们出了线上问题，而不是等到业务侧反馈。所以，我们需要对核心接口做好监控告警的功能。

2、如果是业务代码层面的监控报警，那我们应该是可以很快地定位出是哪儿的问题，毕竟告警逻辑都是我们写的嘛。如果是服务器资源/所依赖的中间件告警，那我们可能就要花点时间去排查啦。

3、不管怎么样，无论是系统告警还是是业务侧反馈系统或者接口出了问题。我们要想想在近期有没有发布过系统，如果近期发布过系统，判断能不能立马回滚到上一个版本，恢复系统平稳正常运行（在线上环境下，可用性是相当重要的）。回滚的时候要考虑接口有无依赖性，是否需要跟业务侧同步此次的回滚以及做相关的配合。

4、因为线上大多数的问题都来源于系统的变更，可能我们只是变更了很少的代码，但只要有一丝的逻辑没留意到，就真的很可能会导致出现问题，回滚很可能是最快能恢复线上正常运行的办法。

5、如果近期都没发布过系统，是系统告的警，那追踪下告警和报错日志，应该是可以很快地就能定位出问题。

6、如果不是系统告的警，是业务侧反馈出了问题，那这时候需要业务侧明确是哪个具体的功能/接口出了问题，有没有保留请求入参，有没有返回错误的信息，有何现象

7、知道了问题的现象之后，就需要根据经验排查可能是哪块出了问题了。我的经验一般是：先查存储侧有没有瓶颈(MySQL 的CPU有没有飙高，主从同步延迟是否很大，有没有慢SQL。Redis是不是内存满了，走了淘汰策略。搜索引擎有没有慢Query)，把该服务所依赖的中间件的指标看一遍，这个过程中也要去看看服务接口的QPS/RT相关的监控。如果有某项指标不对劲，那顺着写入逻辑也应该很快能看出来

8、一般到这里，大多数的问题都能查出来。可能是逻辑本身的问题，可能是请求入参导致慢查询，可能是中间件的网络抖动，可能是突发或者异常请求的问题。

9、如果都不是，回归到应用和机器本身的监控：应用GC的表现、机器本身的网络/磁盘/内存/CPU 各种的指标有没有发现异常的情况。这里可能是需要运维侧一起配合看看有没有做过改动。

10、要是还定位不出来，看能不能复现，能复现都好说，肯定是能解决的。

11、要是不能复现，只能在怀疑的地方打上详细的日志再好好观察（问题定位不出来，很多时候就是日志不够详细，而日志在正常情况下也不应该打太多）

## 6.什么是幂等和去重
面试官：要不你来讲讲你最近在看的点呗？可以拉出来一起讨论下

候选者：最近在看「去重」和「幂等」相关的内容

面试官：那你就先来聊聊你对「去重」和「幂等」的理解吧

候选者：我认为「幂等」和「去重」它们很像，我也说不出他们之间的严格区别

候选者：我说下我个人的理解，我也不知道对不对

候选者：「去重」是对请求或者消息在「一定时间内」进行去重「N次」

候选者：「幂等」则是保证请求或消息在「任意时间内」进行处理，都需要保证它的结果是一致的

候选者：不论是「去重」还是「幂等」，都需要对有一个「唯一 Key」，并且有地方对唯一Key进行「存储」

候选者：以项目举例，我维护的「消息管理平台」是有「去重」的功能的：「5分钟相同内容消息去重」「1小时内模板去重」「一天内渠道达到N次阈值去重」…

候选者：再次强调下「幂等」和「去重」的本质：「唯一Key」+「存储」

面试官：那你是怎么做的呢

候选者：不同的业务场景，唯一Key是不一样的，由业务决定

候选者：存储选择挺多的，比如「本地缓存」/「Redis」/「MySQL」/「HBase」等等，具体选取什么，也跟业务有关

候选者：比如说，在「消息管理平台」这个场景下，我存储选择的「Redis」（读写性能优越），Redis也有「过期时间」方便解决「一定时间内」的问题

候选者：而唯一Key，自然就是根据不同的业务构建不同的。

候选者：比如说「5分钟相同内容消息去重」，我直接MD5请求参数作为唯一Key。「1小时模板去重」则是「模板ID+userId」作为唯一Key，「一天内渠道去重」则是「渠道ID+userId」作为唯一Key…

面试官：既然提到了「去重」了，你听过布隆过滤器吗？

候选者：自然是知道的啦

面试官：来讲讲布隆过滤器吧，你为什么不用呢？

候选者：布隆过滤器的底层数据结构可以理解为bitmap，bitmap也可以简单理解为是一个数组，元素只存储0和1，所以它占用的空间相对较小

候选者：当一个元素要存入bitmap时，其实是要去看存储到bitmap的哪个位置，这时一般用的就是哈希算法，存进去的位置标记为1

候选者：标记为1的位置表示存在，标记为0的位置标示不存在

候选者：布隆过滤器是可以以较低的空间占用来判断元素是否存在进而用于去重，但是它也有对应的缺点

候选者：只要使用哈希算法离不开「哈希冲突」，导致有存在「误判」的情况

候选者：在布隆过滤器中，如果元素判定为存在，那该元素「未必」真实存在。如果元素判定为不存在，那就肯定是不存在

候选者：这应该不用我多解释了吧？（结合「哈希算法」和「标记为1的位置表示存在，标记为0的位置标示不存在」这两者就能得出上面结论）

候选者：布隆过滤器也不能「删除」元素（也是哈希算法的局限性，在布隆过滤器中是不能准确定位一个元素的）

候选者：如果要用的话，布隆过滤器的实现可以直接上Guava已经实现好的，不过这个是单机的

候选者：而分布式下的布隆过滤器，一般现在会用Redis，但也不是没个公司都会部署布隆过滤器的Redis版（还是有局限，像我以前公司就没有）

候选者：所以，目前我负责的项目都是没有用布隆过滤器的（：

候选者：如果「去重」开销比较大，可以考虑建立「多层过滤」的逻辑

候选者：比如，先看看『本地缓存』能不能过滤一部分，剩下「强校验」交由『远程存储』（常见的Redis或者DB）进行二次过滤

面试官：嗯，那我就想起你上一次回答Kafka的时候了

面试官：当时你说在处理订单时实现了at least one + 幂等

面试官：幂等处理时：前置过滤使用的是Redis，强一致校验时使用的是DB唯一索引，也是为了提高性能，对吧？

面试官：唯一Key 好像就是 「订单编号 + 订单状态」

候选者：面试官你记性真的好！

候选者：一般我们需要对数据强一致性校验，就直接上MySQL（DB），毕竟有事务的支持

候选者：「本地缓存」如果业务适合，那可以作为一个「前置」判断

候选者：Redis高性能读写，前置判断和后置均可（：

候选者：而HBase则一般用于庞大数据量的场景下（Redis内存太贵，DB不够灵活也不适合单表存大量数据）

候选者：至于幂等，一般的存储还是「Redis」和「数据库」

候选者：最最最最常见的就是数据库「唯一索引」来实现幂等（我所负责的好几个项目都是用这个）

候选者：构建「唯一Key」是业务相关的事了（：一般是用自己的业务ID进行拼接，生成一个”有意义”的唯一Key

候选者：当然，也有用「Redis」和「MySQL」实现分布式锁来实现幂等的（：

候选者：但Redis分布式锁是不能完全保证安全的，而MySQL实现分布式锁（乐观锁和悲观锁还是看业务吧，我是没用到过的）

候选者：网上有很多实现「幂等」的方案，本质上都是围绕着「存储」和「唯一Key」做了些变种，然后取了个名字…

候选者：总的来说，换汤不换药（：

---------
## 网络
> [计算机网络](https://stubbornwdb.github.io/MyNotes/#/notes/计算机网络3.md) 

## 操作系统
> [计算机操作系统](https://stubbornwdb.github.io/MyNotes/#/notes/计算机操作系统.md) </br>
> [Linux](https://stubbornwdb.github.io/MyNotes/#/notes/Linux.md)

## 数据库
> [MySQL](https://stubbornwdb.github.io/MyNotes/#/notes/MySQL.md) </br>
> [Redis面经](https://stubbornwdb.github.io/MyNotes/#/mynotes/redis/RedisQuestion.md)

## 消息队列
> [消息队列](https://stubbornwdb.github.io/MyNotes/#/notes/消息队列.md)

## Go
> [Go](https://stubbornwdb.github.io/MyNotes/#/mynotes/Go/go-interview.md)

## 系统设计
> [系统设计](https://stubbornwdb.github.io/MyNotes/#/mynotes/SystemDesign/SystemDesign.md)
