# 1 Redis缓存雪崩，穿透，击穿，降级，预热等解决方案
## 1.1 缓存雪崩

**1、什么是缓存雪崩？**

缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。由于原有缓存失效，新缓存未到期间所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。

**2、缓存雪崩问题排查**

- 在一个较短的时间内，缓存中较多的key集中过期
- 此周期内请求访问过期的数据，redis未命中，redis向数据库获取数据
- 数据库同时接收到大量的请求无法及时处理
- Redis大量请求被积压，开始出现超时现象
- 数据库流量激增，数据库崩溃
- 重启后仍然面对缓存中无数据可用
- Redis服务器资源被严重占用，Redis服务器崩溃
- Redis集群呈现崩塌，集群瓦解
- 应用服务器无法及时得到数据响应请求，来自客户端的请求数量越来越多，应用服务器崩溃
- 应用服务器，redis，数据库全部重启，效果不理想

**3、有什么解决方案来防止缓存雪崩？**

- **更多的页面静态化处理**

- **构建多级缓存架构** Nginx缓存+redis缓存+ehcache缓存

- **检测Mysql严重耗时业务进行优化** 对数据库的瓶颈排查：例如超时查询、耗时较高事务等

- **灾难预警机制**

- - 监控redis服务器性能指标
  - CPU占用、CPU使用率
  - 内存容量
  - 查询平均响应时间
  - 线程数

- **限流、降级** 短时间范围内牺牲一些客户体验，限制一部分请求访问，降低应用服务器压力，待业务低速运转后再逐步放开访问

- **LRU与LFU切换** **2. 数据有效期策略调整**

- - 根据业务数据有效期进行分类错峰，A类90分钟，B类80分钟，C类70分钟
  - 过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量

- **超热数据使用永久key**

- **定期维护（自动+人工）** 对即将过期数据做访问量分析，确认是否延时，配合访问量统计，做热点数据的延时 **5. 加锁**

**4.总结**

缓存雪崩就是瞬间过期数据量太大，导致对数据库服务器造成压力。如能够有效避免过期时间集中，可以有效解决雪崩现象的出现（约40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整。

## 1.2 缓存预热

**1.什么是缓存预热**

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。**用户直接查询事先被预热的缓存数据。

如果不进行预热， 那么 Redis 初识状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。

**2.问题排查**

1. 请求数量较高
2. 主从之间数据吞吐量较大，数据同步操作频度较高

**3.有什么解决方案？**

**前置准备工作：**

- 日常例行统计数据访问记录，统计访问频度较高的热点数据

- 利用LRU数据删除策略，构建数据留存队列

```
  例如：storm与kafka配合
```

**准备工作：**

- 将统计结果中的数据分类，根据级别，redis优先加载级别较高的热点数据 
- 利用分布式多服务器同时进行数据读取，提速数据加载过程
- 热点数据主从同时预热

**实施：** 

-  使用脚本程序固定触发数据预热过程 

- 如果条件允许，使用了CDN（内容分发网络），效果会更好

**4.总结**

缓存预热就是系统启动前，提前将相关的缓存数据直接加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据

## 1.3 缓存穿透

**1、什么是缓存穿透？**

缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到对应key的value，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请求就绕过缓存直接查数据库

**2、有什么解决方案来防止缓存穿透？**

> **1、缓存空值**
>
> 如果一个查询返回的数据为空（不管是数据不存在，还是系统故障）我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过5分钟。通过这个设置的默认值存放到缓存，这样第二次到缓存中获取就有值了，而不会继续访问数据库
>
> **2、采用布隆过滤器BloomFilter**
>
> **优势：**占用内存空间很小，位存储；性能特别高，使用key的hash判断key存不存在
>
> 将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力
>
> 在缓存之前在加一层BloomFilter，在查询的时候先去BloomFilter去查询key是否存在，如果不存在就直接返回，存在再去查询缓存，缓存中没有再去查询数据库

**3.总结**

缓存击穿访问了不存在的数据，跳过了合法数据的redis数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时报警。应对策略应该在临时预案防范方面多做文章。无论是黑名单还是白名单，都是对整体系统的压力，警报解除后尽快移除。

## 1.4 缓存降级

降级的情况，就是缓存失效或者缓存服务挂掉的情况下，我们也不去访问数据库。我们直接访问内存部分数据缓存或者直接返回默认数据。

**举例来说：**

> 对于应用的首页，一般是访问量非常大的地方，首页里面往往包含了部分推荐商品的展示信息。这些推荐商品都会放到缓存中进行存储，同时我们为了避免缓存的异常情况，对热点商品数据也存储到了内存中。同时内存中还保留了一些默认的商品信息。如下图所示：

<div align="center"> <img src="/mypics/redis04.jpg"/> </div><br>

降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。

## 1.5 缓存击穿

**1、什么是缓存击穿？**

在平常高并发的系统中，大量的请求同时查询一个key时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿

**2、问题排查**

- Redis中某个key过期，该key访问量巨大
- 多个数据请求从服务器直接压到Redis后，均未命中
- Redis在短时间内发起了大量对数据库中同一数据的访问

**3、如何解决**

- 使用互斥锁(mutex key)

这种解决方案思路比较简单，就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据就可以了。如果是单机，可以用synchronized或者lock来处理，如果是分布式环境可以用分布式锁就可以了（分布式锁，可以用memcache的add, redis的setnx, zookeeper的添加节点操作）。

- "提前"使用互斥锁(mutex key)

在value内部设置1个超时值(timeout1), timeout1比实际的redis timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中

- "永远不过期"

  - 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。

  -  从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期

  

- **缓存屏障**

```
class MyCache{

    private ConcurrentHashMap<String, String> map;

    private CountDownLatch countDownLatch;

    private AtomicInteger atomicInteger;

    public MyCache(ConcurrentHashMap<String, String> map, CountDownLatch countDownLatch,
                   AtomicInteger atomicInteger) {
        this.map = map;
        this.countDownLatch = countDownLatch;
        this.atomicInteger = atomicInteger;
    }

    public String get(String key){

        String value = map.get(key);
        if (value != null){
            System.out.println(Thread.currentThread().getName()+"\t 线程获取value值 value="+value);
            return value;
        }
        // 如果没获取到值
        // 首先尝试获取token，然后去查询db，初始化化缓存；
        // 如果没有获取到token，超时等待
        if (atomicInteger.compareAndSet(0,1)){
            System.out.println(Thread.currentThread().getName()+"\t 线程获取token");
            return null;
        }

        // 其他线程超时等待
        try {
            System.out.println(Thread.currentThread().getName()+"\t 线程没有获取token，等待中。。。");
            countDownLatch.await();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        // 初始化缓存成功，等待线程被唤醒
        // 等待线程等待超时，自动唤醒
        System.out.println(Thread.currentThread().getName()+"\t 线程被唤醒，获取value ="+map.get("key"));
        return map.get(key);
    }

    public void put(String key, String value){

        try {
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        map.put(key, value);

        // 更新状态
        atomicInteger.compareAndSet(1, 2);

        // 通知其他线程
        countDownLatch.countDown();
        System.out.println();
        System.out.println(Thread.currentThread().getName()+"\t 线程初始化缓存成功！value ="+map.get("key"));
    }

}

class MyThread implements Runnable{

    private MyCache myCache;

    public MyThread(MyCache myCache) {
        this.myCache = myCache;
    }

    @Override
    public void run() {
        String value = myCache.get("key");
        if (value == null){
            myCache.put("key","value");
        }

    }
}

public class CountDownLatchDemo {
    public static void main(String[] args) {

        MyCache myCache = new MyCache(new ConcurrentHashMap<>(), new CountDownLatch(1), new AtomicInteger(0));

        MyThread myThread = new MyThread(myCache);

        ExecutorService executorService = Executors.newFixedThreadPool(5);
        for (int i = 0; i < 5; i++) {
            executorService.execute(myThread);
        }
    }
}
```

**4.总结**

缓存击穿就是单个高热数据过期的瞬间，数据访问量较大，未命中redis后，发起了大量对同一数据的数据库访问，导致对数据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个key的过期监控难度较高，配合雪崩处理策略即可。



# 2. 如何保证Redis缓存和数据库的双写一致性？

在数据库+缓存模式下，当数据库中的数据需要更新时，缓存里的数据怎么处理？如何保证缓存和数据库中数据的一致性？常用的解决方案有两种：

- **先删除缓存，再更新数据库；**

- **先更新数据库，再删除缓存；**

## 2.1 先删除缓存，再更新数据库

理想的流程是这样的：先删除缓存，再更新数据库，更新完数据库后，当有请求进来的时候发现缓存中没有数据，于是去查数据库，读取到更新后的新数据放回缓存再返回。这只是理想化的流程，如果只是简单的这样做，我们看看会存在什么问题呢？

在高并发场景下，假设有两个线程，线程A先删除缓存，再去更新数据库，在线程A删除缓存成功但更新数据库还未提交的时候，进来了一个线程B读取数据，发现缓存中没有数据，于是去读数据库，这时B读到的是旧数据，然后再将这个旧数据放回缓存，等A更新数据库完成以后，数据库和缓存中的数据就是不一致的。如果该缓存还没有设置过期时间，那这个数据将一直脏下去。

这个问题可以用"延时双删策略"来解决，A线程先删除缓存，再更新数据库，数据库更新完成后休眠200ms，再次删除缓存，这样做的目的就是保证中间产生的脏数据最后被再次删除。但这个200ms要根据自己的业务情况来确定。

还有一个问题，在延时双删策略第二次删除缓存的时候删除失败怎么办？这种情况可以提供一个"重试保障机制"，如果删除失败，可以将删除失败的key发送到消息队列，再次重试操作。

## 2.2 先更新数据库，再删除缓存

理想的流程是这样的：先更新数据库，再删除缓存，当再有请求进来的时候发现缓存中没有数据，于是去查数据库，再将更新后的新数据放到缓存返回。

这种策略就是典型的“Cache Aside 模式”，更新缓存的设计模式有四种：Cache aside, Read through, Write through和Write behind caching。这四种模式并不仅仅适用于数据库和缓存之间的更新，它们设计的初衷是基于计算机体系结构的，比如CPU的缓存，硬盘文件系统中的缓存，硬盘上的缓存，数据库中的缓存等。所以，它们都是非常权威的，而且历经了长时间考验的最佳实践，我们直接遵从就可以了，没必要重复造轮子。

推荐阅读：《缓存更新的套路-https://coolshell.cn/articles/17416.html》

FaceBook在论文《Scaling Memcache at Facebook》中说过，他们采用的就是Cache Aside 策略。

※ 先更新数据库，再删除缓存有什么问题？

**1、并发问题**

从理论上来讲，Cache Aside也有可能发生并发问题，假设有两个线程，A线程读取数据，没有命中缓存，然后就去查数据库，在A查询数据库还没有返回结果的时候，另一个线程B执行一个写操作，更新完数据库后，让缓存失效（实际上这时候缓存已经是失效的，因为A在读的时候就没有命中缓存），然后，之前的线程A读取数据库返回了结果，再把老的数据放进缓存，这时候缓存中放得是A读出来的老数据，而数据库中存的是B更新后的新数据，数据库和缓存数据不一致。

这种情况理论上会出现，不过，实际上出现的概率可能非常非常低。因为上述并发场景的出现，需要同时具备条件：1、某线程在读缓存时缓存失效了，而且刚好并发着有一个写操作；2、读操作在写操作之前开始，在写操作之后结束，也就是说读操作的耗时大于写操作；出现这种场景的概率还是很低的。

如果要解决Cache Aside的并发问题，可以通过2PC或是Paxos协议保证一致性，或者尽力的降低并发时脏数据的概率，而Facebook使用的就是降低概率的玩法，因为2PC太慢，而Paxos太复杂。

**2、数据库更新成功，删除缓存失败怎么办？**

如果发生这种情况，数据库中存放的是更新后的数据，缓存因为没有删除成功存放的还是老数据，这个问题怎么解决呢，我们可以提供一种保障性的"重试机制"。

方案一、基于MQ实现

<div align="center"> <img src="/mypics/redis07.jpg"/> </div><br>

(1).更新数据库数据;

(2).删除缓存失败;

(3).当删除缓存数据失败时，应用程序发送消息，将需要删除的 Key 发送到MQ中;

(4).应用程序自己消费消息;

(5).应用接收到消息后，再次尝试删除缓存，如果再次删除失败，可重发消息多次尝试;

方案二、基于 阿里Canal 实现

Canal是阿里开发的基于数据库增量日志解析，提供增量数据的订阅&消费的中间件，目前主要支持MySQL的binlog解析。从下图可以看出，基于Canal的实现方案完全避免了对业务代码的侵入，核心业务代码只管更新数据库，其他的不用care。

<div align="center"> <img src="/mypics/redis08.jpg"/> </div><br>

(1).更新数据库数据；

(2).MySQL 将数据更新日志写入 binlog 中；

(3).Canal 订阅 & 消费 MySQL binlog；

(4).Canal 解析binlog，提取出更新数据的key发送给另一段非业务代码；

(5).非业务代码尝试删除缓存操作，发现删除失败；

(6).将需要删除缓存的 Key 发送到消息队列 (MQ) 中；

(7).消费消息，从队列中拿到要删除的缓存key;

(8).拿到要删除的key后，再次尝试删除缓存，如果再次删除失败，可重发消息多次尝试;

总的来说就是先更新数据库，再删除缓存，提供一个"重试保障机制"，如果删除缓存失败时，可以将删除失败的key发送到消息队列，再进行重试删除操作。

# 3. Redis 如何实现高可用
Redis 实现高可用主要有三种方式：主从复制、哨兵模式，以及 Redis 集群。
1）主从复制
将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，这个跟 MySQL 主从复制的原理一样。
2）哨兵模式
使用 Redis 主从服务的时候，会有一个问题，就是当 Redis 的主从服务器出现故障宕机时，需要手动进行恢复，为了解决这个
问题，Redis 增加了哨兵模式 （因为哨兵模式做到了可以监控主从服务器，并且提供自动容灾恢复的功能）。
3）Redis Cluster（集群）
Redis Cluster 是一种分布式去中心化的运行模式，是在 Redis 3.0 版本中推出的 Redis 集群方案，它将数据分布在不同
的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。


## 3.1 主从复制
### 3.1.1 为什么要用主从复制
**存在问题：**
在现有企业中80%公司大部分使用的是redis单机服务，在实际的场景当中单一节点的redis容易面临风险。

- 机器故障。我们部署到一台 Redis 服务器，当发生机器故障时，需要迁移到另外一台服务器并且要保证数据是同步的。而数据是最重要的，如果你不在乎，基本上也就不会使用 Redis 了。

- 容量瓶颈。当我们有需求需要扩容 Redis 内存时，从 16G 的内存升到 64G，单机肯定是满足不了。当然，你可以重新买个 128G 的新机器。

**解决办法**
要实现分布式数据库的更大的存储容量和承受高并发访问量，我们会将原来集中式数据库的数据分别存储到其他多个网络节点上。Redis 为了解决这个单一节点的问题，也会把数据复制多个副本部署到其他节点上进行复制，实现 Redis的高可用，实现对数据的冗余备份，从而保证数据和服务的高可用。

### 3.1.2 什么是主从复制

<div align="center"> <img src="/mypics/redis09.jpg"/> </div><br>

主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)，数据的复制是单向的，只能由主节点到从节点。

默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。

**主从复制的作用**

- 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。

- 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。

- 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。

- 读写分离：可以用于实现读写分离，主库写、从库读，读写分离不仅可以提高服务器的负载能力，同时可根据需求的变化，改变从库的数量。

- 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。

### 3.1.3 主从复制启用

从节点开启主从复制，有3种方式：

1、配置文件：在从服务器的配置文件中加入 slaveof<masterip><masterport>。

2、启动命令：redis-server启动命令后加入 --slaveof<masterip><masterport>。

3、客户端命令：Redis服务器启动后，直接通过客户端执行命令 slaveof<masterip><masterport>，则该Redis实例成为从节点。

通过 info replication 命令可以看到复制的一些信息。

## 3.1.4 主从复制原理

主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段。

在从节点执行 slaveof 命令后，复制过程便开始运作，下面图示可以看出复制过程大致分为6个过程。

主从配置之后的日志记录也可以看出这个流程。

1、保存主节点（master）信息

执行 slaveof 后 Redis 会打印如下日志：

2、从节点与主节点建立网络连接

从节点（slave）内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接。

从节点与主节点建立网络连接。

从节点会建立一个 socket 套接字，从节点建立了一个端口为51234的套接字，专门用于接受主节点发送的复制命令。从节点连接成功后打印如下日志：

如果从节点无法建立连接，定时任务会无限重试直到连接成功或者执行 slaveofnoone 取消复制。

关于连接失败，可以在从节点执行 info replication 查看 master_link_down_since_seconds 指标，它会记录与主节点连接失败的系统时间。从节点连接主节点失败时也会每秒打印如下日志，方便发现问题：

```
# Error condition on socket for SYNC: {socket_error_reason}
```

3、发送 ping 命令

连接建立成功后从节点发送 ping 请求进行首次通信， ping 请求主要目的如下：

检测主从之间网络套接字是否可用。

检测主节点当前是否可接受处理命令。

如果发送 ping 命令后，从节点没有收到主节点的 pong 回复或者超时，比如网络超时或者主节点正在阻塞无法响应命令，从节点会断开复制连接，下次定时任务会发起重连。

从节点发送的 ping 命令成功返回，Redis 打印如下日志，并继续后续复制流程：

4、权限验证

如果主节点设置了 requirepass 参数，则需要密码验证，从节点必须配置 masterauth 参数保证与主节点相同的密码才能通过验证。如果验证失败复制将终止，从节点重新发起复制流程。

5、同步数据集

主从复制连接正常通信后，对于首次建立复制的场景，主节点会把持有的数据全部发送给从节点，这部分操作是耗时最长的步骤。

6、命令持续复制

当主节点把当前的数据同步给从节点后，便完成了复制的建立流程。接下来主节点会持续地把写命令发送给从节点，保证主从数据一致性。

## 3.2 哨兵模式
- 使用哨兵模式在数据上有副本数据做保证，在可用性上又有哨兵监控，一旦 master 宕机会选举 salve 节点为 master 节点，
这种已经满足了我们的生产环境需要，那为什么还需要使用集群模式呢？
哨兵模式归根结底还是主从模式，在主从模式下我们可以通过增加 salve 节点来扩展读并发能力，但是没办法扩展写能力和存储能力，
存储能力只能是 master 节点能够承载的上限。所以为了扩展写能力和存储能力，我们就需要引入集群模式。

- 集群中那么多 Master 节点，Redis Cluster 在存储的时候如何确定选择哪个节点呢？
  Redis Cluster 采用的是类一致性哈希算法实现节点选择的，至于什么是一致性哈希算法你自己回去看看。

Redis Cluster 将自己分成了 16384 个 Slot（槽位），哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个
哈希槽中，具体执行过程分为两大步。
1）根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。
2）再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。
每个 Redis 节点负责处理一部分槽位，假如你有三个 master 节点 ABC，每个节点负责的槽位如下：

节点	处理槽位
A	0-5000
B	5001 - 10000
C	10001 - 16383
这样就实现了 cluster 节点的选择。


# 4. Redis持久化

## 4.1  Redis 是如何实现数据不丢失的呢？
Redis 数据是存储在内存中的，为了保证 Redis 数据不丢失，那就要把数据从内存存储到磁盘上，以便在服务器重启后还能够从磁盘中恢复原有数据，
这就是 Redis 的数据持久化。Redis 数据持久化有三种方式。
1）AOF 日志（Append Only File，文件追加方式）：记录所有的操作命令，并以文本的形式追加到文件中。
2）RDB 快照（Redis DataBase）：将某一个时刻的内存数据，以二进制的方式写入磁盘。
3）混合持久化方式：Redis 4.0 新增了混合持久化的方式，集成了 RDB 和 AOF 的优点。


持久化过程大致是：

1. 客户端向数据库 **发送写命令** *(数据在客户端的内存中)*
2. 数据库 **接收** 到客户端的 **写请求** *(数据在服务器的内存中)*
3. 数据库 **调用系统 API** 将数据写入磁盘 *(数据在内核缓冲区中)*
4. 操作系统将 **写缓冲区** 传输到 **磁盘控控制器** *(数据在磁盘缓存中)*
5. 操作系统的磁盘控制器将数据 **写入实际的物理媒介** 中 *(数据在磁盘中)*

## 4.1  RDB 快照
RDB 采用的是内存快照的方式，它记录的是某一时刻的数据，而不是操作，所以采用 RDB 方法做故障恢复时只需要直接把RDB文件读入内存即可，实现快速恢复。

RDB 做快照时会阻塞线程吗？
Redis 提供了两个命令来生成 RDB 快照文件，分别是 save 和 bgsave。save 命令在主线程中执行，会导致阻塞。而 bgsave 命令则会创建一个子进程，
用于写入 RDB 文件的操作，避免了对主线程的阻塞，这也是 Redis RDB 的默认配置。

RDB 做快照的时候数据能修改吗？
save 是同步的会阻塞客户端命令，bgsave 的时候是可以修改的。

那 Redis 是怎么解决在 bgsave 做快照的时候允许数据修改呢？
这里主要是利用 bgsave 的子线程实现的，具体操作如下：
如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响；
如果主线程执行写操作，则被修改的数据会复制一份副本，然后 bgsave 
子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。
要注意，Redis 对 RDB 的执行频率非常重要，因为这会影响快照数据的完整性以及 Redis 
的稳定性，所以在 Redis 4.0 后，增加了 AOF 和 RDB 混合的数据持久化机制： 把数据
以 RDB 的方式写入文件，再将后续的操作命令以 AOF 的格式存入文件，既保证了 Redis 
重启速度，又降低数据丢失风险。


**Redis 快照** 是最简单的 Redis 持久性模式。当满足特定条件时，它将生成数据集的时间点快照，例如，如果先前的快照是在2分钟前创建的，并且现在已经至少有 *100* 次新写入，则将创建一个新的快照。此条件可以由用户配置 Redis 实例来控制，
也可以在运行时修改而无需重新启动服务器。快照作为包含整个数据集的单个 `.rdb` 文件生成。
但我们知道，Redis 是一个 **单线程** 的程序，这意味着，我们不仅仅要响应用户的请求，还需要进行内存快照。而后者要求 Redis 必须进行 IO 操作，这会严重拖累服务器的性能。
还有一个重要的问题是，我们在 **持久化的同时**，**内存数据结构** 还可能在 **变化**，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它删除了，可是这才刚持久化结束，咋办？
使用系统多进程 COW(Copy On Write) 机制 | fork 函数
操作系统多进程 **COW(Copy On Write) 机制** 拯救了我们。**Redis** 在持久化时会调用 `glibc`的函数 `fork` 产生一个子进程，简单理解也就是基于当前进程 **复制** 了一个进程，主进程和子进程会共享内存里面的代码块和数据段：
fork 的大致过程是 分配新的内存块和内核数据结构给子进程，将父进程部分数据结构内容拷贝至子进程，然后添加子进程到列表当中，Fork再返回，开始调度器的调度。
（为什么 fork 成功调用后会有两个返回值呢？ 因为子进程在复制时复制了父进程的堆栈段，所以两个进程都停留在了 `fork` 函数中 *(都在同一个地方往下继续"同时"执行)*，等待返回，所以 **一次在父进程中返回子进程的 pid，另一次在子进程中返回零，系统资源不够时返回负数**。）
所以 **快照持久化** 可以完全交给 **子进程** 来处理，**父进程** 则继续 **处理客户端请求**。**子进程** 做数据持久化，它 **不会修改现有的内存数据结构**，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是 **父进程** 不一样，它必须持续服务客户端请求，
然后对 **内存数据结构进行不间断的修改**。 这个时候就会使用操作系统的 COW 机制来进行 **数据段页面** 的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复 制一份分离出来，然后 **对这个复制的页面进行修改**。
这时 **子进程** 相应的页面是 **没有变化的**，还是进程产生时那一瞬间的数据。 子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 **Redis** 的持久化 **叫「快照」的原因**。接下来子进程就可以非常安心的遍历数
据了进行序列化写磁盘了。

## 4.2  AOF 
AOF 采用的是写后日志的方式，Redis 先执行命令把数据写入内存，然后再记录日志到文件中。AOF 日志记录的是操作命令，不是实际的数据，如果采用 AOF 方法做故障恢复时需要将全量日志都执行一遍。

AOF 采用的是 “写后日志” 的方式，我们平时用的 MySQL 则采用的是 “写前日志”，那 Redis 为什么要先执行命令，再把数据写入日志呢？
这个主要是由于 Redis 在写入日志之前，不对命令进行语法检查，所以只记录执行成功的命令，避免出现记录错误命令的情况，而且在命令执行后再写日志不会阻塞当前的写操作。

那后写日志又有什么风险呢？
后写日志主要有两个风险可能会发生：
数据可能会丢失：如果 Redis 刚执行完命令，此时发生故障宕机，会导致这条命令存在丢失的风险。
可能阻塞其他操作：AOF 日志其实也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。


**快照不是很持久**。如果运行 Redis 的计算机停止运行，电源线出现故障或者您 `kill -9` 的实例意外发生，则写入 Redis 的最新数据将丢失。尽管这对于某些应用程序可能不是什么大问题，但有些使用案例具有充分的耐用性，在这些情况下，快照并不是可行的选择。
**AOF(Append Only File - 仅追加文件)** 它的工作方式非常简单：每次执行 **修改内存** 中数据集的写操作时，都会 **记录** 该操作。假设 AOF 日志记录了自 Redis 实例创建以来 **所有的修改性指令序列**，那么就可以通过对一个空的 Redis 实例 **顺序执行所有的指令**，也就是 **「重放」**，来恢复 Redis 当前实例的内存数据结构的状态。
当 Redis 收到客户端修改指令后，会先进行参数校验、逻辑处理，如果没问题，就 **立即** 将该指令文本 **存储** 到 AOF 日志中，也就是说，**先执行指令再将日志存盘**。这一点不同于 `MySQL`、`LevelDB`、`HBase` 等存储引擎
如果我们先存储日志再做逻辑处理，这样就可以保证即使宕机了，我们仍然可以通过之前保存的日志恢复到之前的数据状态，但是 **Redis 为什么没有这么做呢？**（仅仅是因为，由于AOF文件会比较大，为了避免写入无效指令（错误指令），必须先做指令检查？如何检查，只能先执行了。因为语法级别检查并不能保证指令的有效性，比如删除一个不存在的key。而MySQL这种是因为它本身就维护了所有的表的信息，所以可以语法检查后过滤掉大部分无效指令直接记录日志，然后再执行。）
**AOF 重写**
**Redis** 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 **AOF 日志 "瘦身"**。Redis提供了 `bgrewriteaof` 指令用于对 AOF 日志进行瘦身。其 **原理** 就是 **开辟一个子进程**对内存进行 **遍历** 转换成一系列 Redis 的操作指令，**序列化到一个新的 AOF 日志文件** 中。序列化完毕后再将操作期间发生的 **增量 AOF 日志** 追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。
**fsync**
AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。
就像我们 *上方第四步* 描述的那样，我们需要借助 `glibc` 提供的 `fsync(int fd)` 函数来讲指定的文件内容 **强制从内核缓存刷到磁盘**。但 **"强制开车"** 仍然是一个很消耗资源的一个过程，需要 **"节制"**！通常来说，生产环境的服务器，Redis 每隔 1s 左右执行一次 `fsync` 操作就可以了。
Redis 同样也提供了另外两种策略，一个是 **永不** **`fsync`**，来让操作系统来决定合适同步磁盘，很不安全，另一个是 **来一个指令就** **`fsync` 一次**，非常慢。但是在生产环境基本不会使用，了解一下即可。

## 4.3 Redis 4.0 混合持久化

重启 Redis 时，我们很少使用 `rdb` 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 `rdb` 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。

**Redis 4.0** 为了解决这个问题，带来了一个新的持久化选项——**混合持久化**。将 `rdb` 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是 **自持久化开始到持久化结束** 的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小：

于是在 Redis 重启的时候，可以先加载 `rdb` 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。



# 5. Redis单线程问题

## 5.1 Redis 是单线程还是多线程
Redis 不同版本之间采用的线程模型是不一样的，在 Redis4.0 版本之前使用的是单线程模型，在 4.0 版本
之后增加了多线程的支持。在 4.0 之前虽然我们说 Redis 是单线程，也只是说它的网络 I/O 线程以及 Set
和 Get 操作是由一个线程完成的。但是 Redis 的持久化、集群同步还是使用其他线程来完成。
4.0 之后添加了多线程的支持，主要是体现在大数据的异步删除功能上，例如 unlink key、flushdb async、
flushall async 等

注：UNLINK key 是 Redis 的一个命令，它可以异步地删除一个给定的 key。与 DELETE key 不同的是，
UNLINK key 命令不会阻塞 Redis 服务器，而是将删除操作放到一个异步任务队列中处理。这个命令的作用
是在不阻塞 Redis 服务器的情况下删除大量的 key，从而减少 Redis 服务器的阻塞时间，提高 Redis 的性能。
FLUSHDB ASYNC 和 FLUSHALL ASYNC 命令也是 Redis 的命令，它们可以异步地清空 Redis 数据库中的数据。
与 FLUSHDB 和 FLUSHALL 命令不同的是，FLUSHDB ASYNC 和 FLUSHALL ASYNC 命令也不会阻塞 Redis 服
务器，而是将清空操作放到一个异步任务队列中处理。这个命令的作用是在不阻塞 Redis 服务器的情况下清空 Redis 
数据库中的数据，从而快速地重置 Redis 数据库，或在需要频繁清空 Redis 数据库的场景下提高 Redis的性能。


## 5.2 单线程为什么那么快
4.0之前为什么使用单线程，而且使用单线程还这么快？
选择单线程个人觉得主要是使用简单，不存在锁竞争，可以在无锁的情况下完成所有操作，不存在死锁和线程切换
带来的性能和时间上的开销，但同时单线程也不能完全发挥出多核 CPU 的性能。
至于为什么单线程那么快我觉得主要有以下几个原因：
Redis 的大部分操作都在内存中完成，内存中的执行效率本身就很快，并且采用了高效的数据结构，比如哈希表和跳表。
使用单线程避免了多线程的竞争，省去了多线程切换带来的时间和性能开销，并且不会出现死锁.
采用 I/O 多路复用机制处理大量客户端的 Socket 请求，因为这是基于非阻塞的 I/O 模型，这就让 Redis 可以
高效地进行网络通信，I/O 的读写流程也不再阻塞。


redis 核心就是 如果我的数据全都在内存里，我单线程的去操作就是效率最高的，
为什么呢，因为多线程的本质就是 CPU 模拟出来多个线程的情况，
这种模拟出来的情况就有一个代价，就是上下文的切换，对于一个内存的系统来说，
它没有上下文的切换就是效率最高的。redis 用 单个CPU 绑定一块内存的数据，
然后针对这块内存的数据进行多次读写的时候，都是在一个CPU上完成的，所以它
是单线程处理这个事。在内存的情况下，这个方案就是最佳方案  —— 阿里 沈询


因为一次CPU上下文的切换大概在 1500ns 左右。从内存中读取 1MB 的连续数据，
耗时大约为 250us，假设1MB的数据由多个线程读取了1000次，那么就有1000次时
间上下文的切换， 那么就有1500ns * 1000 = 1500us ，我单线程的读完1MB数
据才250us,你光时间上下文的切换就用了1500us了，我还不算你每次读一点数据的
时间，那什么时候用多线程的方案呢？
答案是：下层的存储等慢速的情况。比如磁盘内存是一个IOPS 非常高的系统，因为
我想申请一块内存就申请一块内存，销毁一块内存我就销毁一块内存，内存的申请和
销毁是很容易的。而且内存是可以动态的申请大小的。

磁盘的特性是：IPOS很低很低，但吞吐量很高。这就意味着，大量的读写操作都必须
攒到一起，再提交到磁盘的时候，性能最高。为什么呢？ 如果我有一个事务组的操作
（就是几个已经分开了的事务请求，比如写读写读写，这么五个操作在一起），在内存
中，因为IOPS非常高，我可以一个一个的完成，但是如果在磁盘中也有这种请求方式的话，
我第一个写操作是这样完成的：我先在硬盘中寻址，大概花费10ms，然后我读一个数据可
能花费1ms然后我再运算（忽略不计），再写回硬盘又是10ms ，总共21ms；第二个操作
去读花了10ms, 第三个又是写花费了21ms ,然后我再读10ms, 写21ms ，五个请求总
共花费83ms，这还是最理想的情况下，这如果在内存中，大概1ms不到。
所以对于磁盘来说，它吞吐量这么大，那最好的方案肯定是我将N个请求一起放在一个buff
里，然后一起去提交。

方法就是用异步：将请求和处理的线程不绑定，请求的线程将请求放在一个buff里，然后
等buff快满了，处理的线程再去处理这个buff。然后由这个buff 统一的去写入磁盘，或
者读磁盘，这样效率就是最高。java里的 IO不就是这么干的么~
对于慢速设备，这种处理方式就是最佳的，慢速设备有磁盘，网络 ，SSD 等等



# 6. 集群

**Redis 支持三种集群方案**

- 主从复制模式
- Sentinel（哨兵）模式
- Cluster 模式



## 6.1 主从复制模式

![img](https://segmentfault.com/img/remote/1460000022808581)

**主从复制的作用**

通过持久化功能，Redis保证了即使在服务器重启的情况下也不会丢失（或少量丢失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。 但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。

为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。

为此， **Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上**。

在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库(slave）。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。

**总结：引入主从复制机制的目的有两个**

- 一个是读写分离，分担 "master" 的读写压力
- 一个是方便做容灾恢复

**主从复制原理**

![img](https://segmentfault.com/img/remote/1460000022808583)

- 从数据库启动成功后，连接主数据库，会发送 SYNC 命令；
- 主数据库接收到 SYNC 命令后，master启动一个后台进程，开始执行 BGSAVE 命令生成 RDB 文件，同时使用缓冲区记录所有新的写命令；
- 主数据库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令；
- 从数据库收到快照文件后丢弃所有旧数据，载入收到的快照；
- 主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令；
- 从数据库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（**从数据库初始化完成**）
- 主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令（**从数据库初始化完成后的操作**）
- 出现断开重连后，2.8之后的版本会将断线期间的命令传给从数据库，进行增量复制。
- 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。

**主从复制优缺点**

**主从复制优点**

- 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离；
- 为了分载 Master 的读操作压力，Slave 服务器可以为客户端提供只读操作的服务，写服务仍然必须由Master来完成；
- Slave 同样可以接受其它 Slaves 的连接和同步请求，这样可以有效的分载 Master 的同步压力；
- Master Server 是以非阻塞的方式为 Slaves 提供服务。所以在 Master-Slave 同步期间，客户端仍然可以提交查询或修改请求；
- Slave Server 同样是以非阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis则返回同步之前的数据；

**主从复制缺点**

- Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（**也就是要人工介入**）；
- 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；
- 如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。
- Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；

## 6.2 Sentinel（哨兵）模式

第一种主从同步/复制的模式，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。

哨兵模式是一种特殊的模式，首先 Redis 提供了哨兵的命令，**哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个 Redis 实例**。

![单哨兵](https://segmentfault.com/img/remote/1460000022808580)

**哨兵模式的作用**

- 通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器；
- 当哨兵监测到 master 宕机，会自动将 slave 切换成 master ，然后通过**发布订阅模式**通知其他的从服务器，修改配置文件，让它们切换主机；

然而一个哨兵进程对Redis服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。

![多哨兵](https://segmentfault.com/img/remote/1460000022808582)

**故障切换的过程**

假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为**主观下线**。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为**客观下线**。这样对于客户端而言，一切都是透明的。

**哨兵模式的工作方式：**

- 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的 Master 主服务器，Slave 从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
- 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
- 如果一个 Master 主服务器被标记为主观下线（SDOWN），则正在监视这个 Master 主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态
- 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认 Master 主服务器进入了主观下线状态（SDOWN）， 则 Master 主服务器会被标记为客观下线（ODOWN）
- 在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有 Master 主服务器、Slave 从服务器发送 INFO 命令。
- 当 Master 主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master 主服务器的所有 Slave 从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
- 若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master 主服务器的客观下线状态就会被移除。若 Master 主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。

**哨兵模式的优缺点**

**优点：**

- 哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。
- 主从可以自动切换，系统更健壮，可用性更高(**可以看作自动版的主从复制**)。

**缺点：**

- Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。

## 6.3 Cluster 集群模式（Redis官方）

Redis Cluster是一种服务器 Sharding 技术，3.0版本开始正式提供。

Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 redis3.0上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，**也就是说每台 Redis 节点上存储不同的内容**。

![image-20200531184321294](https://segmentfault.com/img/remote/1460000022808584)

在这个图中，每一个蓝色的圈都代表着一个 redis 的服务器节点。它们任何两个节点之间都是相互连通的。客户端可以与任何一个节点相连接，然后就可以访问集群中的任何一个节点。对其进行存取和其他操作。

**集群的数据分片**

Redis 集群没有使用一致性 hash，而是引入了哈希槽【hash slot】的概念。

Redis 集群有16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽。集群的每个节点负责一部分hash槽，举个例子，比如当前集群有3个节点，那么：

- 节点 A 包含 0 到 5460 号哈希槽
- 节点 B 包含 5461 到 10922 号哈希槽
- 节点 C 包含 10923 到 16383 号哈希槽

这种结构很容易添加或者删除节点。比如如果我想新添加个节点 D ， 我需要从节点 A， B， C 中得部分槽到 D 上。如果我想移除节点 A ，需要将 A 中的槽移到 B 和 C 节点上，然后将没有任何槽的 A 节点从集群中移除即可。由于从一个节点将哈希槽移动到另一个节点并不会停止服务，所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态。

在 Redis 的每一个节点上，都有这么两个东西，一个是插槽（slot），它的的取值范围是：0-16383。还有一个就是 cluster，可以理解为是一个集群管理的插件。当我们的存取的 Key到达的时候，Redis 会根据 CRC16 的算法得出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作。

**Redis 集群的主从复制模型**

为了保证高可用，redis-cluster集群引入了主从复制模型，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点 ping 一个主节点 A 时，如果半数以上的主节点与 A 通信超时，那么认为主节点 A 宕机了。如果主节点 A 和它的从节点 A1 都宕机了，那么该集群就无法再提供服务了。

**集群的特点**

- 所有的 redis 节点彼此互联(PING-PONG机制)，内部使用二进制协议优化传输速度和带宽。
- 节点的 fail 是通过集群中超过半数的节点检测失效时才生效。
- 客户端与 Redis 节点直连，不需要中间代理层.客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。

# 7. Redis并发竞争key

所谓Redis的并发竞争Key的问题也就是多个系统同时对一个可以进行操作，但是最后执行的顺序和我们期望的顺序不一样，这样也就导致了结果的不同。
可以使用分布式锁(zookeeper和Redis都可以是实现分布式锁，如果不存在Redis的并发问题，不要使用分布式锁，这样会影响性能)

基于zookeeper临时有序结点可以实现分布式锁。大致思想就是：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定结点的目录下，
生成蹭一个唯一的瞬时有序结点。判断是否获取锁的方式很简单。只需要判断有序结点中序号最小的一个。当释放锁定饿时候，只需要将这个瞬时结点删除
即可。同时可以避免服务宕机导致的锁无法释放，而产生的的死锁问题。完成业务流程后，删除对应的子节点释放锁。

基于Redis的分布式锁：

```
/**
 * 使用Redis 实现分布式锁
 * SET key value [EX seconds] [PX milliseconds] [NX|XX]
 *
 * EX seconds – 设置键key的过期时间，单位时秒
 * PX milliseconds – 设置键key的过期时间，单位时毫秒
 * NX – 只有键key不存在的时候才会设置key的值
 * XX – 只有键key存在的时候才会设置key的值
 * @return
 */
```

# 8.底层数据结构

redis我们都知道有5种数据类型，分别是string，list，hash，set，zset，那么你知道它们的底层数据结构实现吗？

redis底层有6种数据结构，分别是简单动态字符串(SDS),链表，字典，跳跃表，整数集合，压缩列表。

每种数据类型都有着2种以上的数据结构实现，在不同状态下会进行数据结构的转换。


## 8.1 SDS

Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），
它是自己构建了一种名为 简单动态字符串（simple dynamic string,SDS）的抽象类型，并将 SDS 作为 Redis的
默认字符串表示。

```
struct sdshdr{
     //记录buf数组中已使用字节的数量
     //等于 SDS 保存字符串的长度
     int len;
     //记录 buf 数组中未使用字节的数量
     int free;
     //字节数组，用于保存字符串
     char buf[];
}
```

**为什么不使用C语言字符串实现，而是使用 SDS呢？这样实现有什么好处？**
**①、常数复杂度获取字符串长度**
由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。而对于 C 语言，
获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。通过 strlen key 命令可以获取 key 的字
符串长度。

**②、杜绝缓冲区溢出**
我们知道在 C 语言中使用 strcat 函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，
就会造成缓冲区溢出。而对于 SDS 数据类型，在进行字符修改的时候，会首先根据记录的 len 属性检查
内存空间是否满足需求，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。

**③、减少修改字符串的内存重新分配次数**
C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有
重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。
而对于SDS，由于len属性和free属性的存在，对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略：
1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。
2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 free 属性将这些字节的数量记录下来，
等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）

**④、二进制安全**
因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；
而所有 SDS 的API 都是以处理二进制的方式来处理 buf 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 
属性表示的长度来判断字符串是否结束。

**⑤、兼容部分 C 字符串函数**
虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库<string.h>中的一部分函数。

## 8.2 链表
链表是一种常用的数据结构，C 语言内部是没有内置这种数据结构的实现，所以Redis自己构建了链表的实现。
链表定义：

```
typedef  struct listNode{
       //前置节点
       struct listNode *prev;
       //后置节点
       struct listNode *next;
       //节点的值
       void *value;  
}listNode
```

通过多个 listNode 结构就可以组成链表，这是一个双向链表，Redis还提供了操作链表的数据结构：

```
typedef struct list{
     //表头节点
     listNode *head;
     //表尾节点
     listNode *tail;
     //链表所包含的节点数量
     unsigned long len;
     //节点值复制函数
     void (*free) (void *ptr);
     //节点值释放函数
     void (*free) (void *ptr);
     //节点值对比函数
     int (*match) (void *ptr,void *key);
}list;
```
Redis链表特性：

①、双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为O(1)。
②、无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结束。　　
③、带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)。
④、多态：链表节点使用 void* 指针来保存节点值，可以保存各种不同类型的值。

## 8.3 字典
字典又称为符号表或者关联数组、或映射（map），是一种用于保存键值对的抽象数据结构。字典中的每一个键 
key 都是唯一的，通过 key 可以对值来进行查找或修改。C 语言中没有内置这种数据结构的实现，
所以字典依然是 Redis自己构建的。Redis 的字典使用哈希表作为底层实现。
哈希表结构定义：
```
typedef struct dictht{
     //哈希表数组
     dictEntry **table;
     //哈希表大小
     unsigned long size;
     //哈希表大小掩码，用于计算索引值
     //总是等于 size-1
     unsigned long sizemask;
     //该哈希表已有节点的数量
     unsigned long used;
}dictht
```

哈希表是由数组 table 组成，table 中每个元素都是指向 dict.h/dictEntry 结构，dictEntry 结构定义如下：

```
typedef struct dictEntry{
     //键
     void *key;
     //值
     union{
          void *val;
          uint64_tu64;
          int64_ts64;
     }v;
 
     //指向下一个哈希表节点，形成链表
     struct dictEntry *next;
}dictEntry
```

key 用来保存键，val 属性用来保存值，值可以是一个指针，也可以是uint64_t整数，也可以是int64_t整数。

注意这里还有一个指向下一个哈希表节点的指针，我们知道哈希表最大的问题是存在哈希冲突，如何解决哈希冲突，
有开放地址法和链地址法。这里采用的便是链地址法，通过next这个指针可以将多个哈希值相同的键值对连接在一起，
用来解决**哈希冲突**。

**①、哈希算法：**Redis计算哈希值和索引值方法如下：

```
#1、使用字典设置的哈希函数，计算键 key 的哈希值``hash = dict->type->hashFunction(key);``#2、使用哈希表的sizemask属性和第一步得到的哈希值，计算索引值``index = hash & dict->ht[x].sizemask;
```

**②、解决哈希冲突：**这个问题上面我们介绍了，方法是链地址法。通过字典里面的 *next 指针指向下一个具有相同索引值的哈希表节点。
**③、扩容和收缩：**当哈希表保存的键值对太多或者太少时，就要通过 rerehash(重新散列）来对哈希表进行相应的扩展或者收缩。具体步骤：

　　1、如果执行扩展操作，会基于原哈希表创建一个大小等于 ht[0].used*2n 的哈希表（也就是每次扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表）。
  相反如果执行的是收缩操作，每次收缩是根据已使用空间缩小一倍创建一个新的哈希表。
　　2、重新利用上面的哈希算法，计算索引值，然后将键值对放到新的哈希表位置上。
　　3、所有键值对都迁徙完毕后，释放原哈希表的内存空间。

**④、触发扩容的条件：**

　　1、服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。

　　2、服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。

　　ps：负载因子 = 哈希表已保存节点数量 / 哈希表大小。
**⑤、渐近式 rehash**

什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。

## 8.4 跳跃表

跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。具有如下性质：

1、由很多层结构组成；

2、每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；

3、最底层的链表包含了所有的元素；

4、如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；

5、链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；

Redis中跳跃表节点定义如下：

```
typedef struct zskiplistNode {
     //层
     struct zskiplistLevel{
           //前进指针
           struct zskiplistNode *forward;
           //跨度
           unsigned int span;
     }level[];
 
     //后退指针
     struct zskiplistNode *backward;
     //分值
     double score;
     //成员对象
     robj *obj;
} zskiplistNode
```

多个跳跃表节点构成一个跳跃表：

```
typedef struct zskiplist{
     //表头节点和表尾节点
     structz skiplistNode *header, *tail;
     //表中节点的数量
     unsigned long length;
     //表中层数最大的节点的层数
     int level;
}zskiplist;
```

①、搜索：从最高层的链表节点开始，如果比当前节点要大和比当前层的下一个节点要小，那么则往下找，也就是和当前层的下一层的节点的下一个节点进行比较，以此类推，一直找到最底层的最后一个节点，如果找到则返回，反之则返回空。

②、插入：首先确定插入的层数，有一种方法是假设抛一枚硬币，如果是正面就累加，直到遇见反面为止，最后记录正面的次数作为插入的层数。当确定插入的层数k后，则需要将新元素插入到从底层到k层。

③、删除：在各个层中找到包含指定值的节点，然后将节点从链表中删除即可，如果删除以后只剩下头尾两个节点，则删除这一层。

## 8.5 整数集合

整数集合（intset）是Redis用于保存整数值的集合抽象数据类型，它可以保存类型为int16_t、int32_t 或者int64_t 的整数值，并且保证集合中不会出现重复元素。

定义如下：

```
typedef struct intset{
     //编码方式
     uint32_t encoding;
     //集合包含的元素数量
     uint32_t length;
     //保存元素的数组
     int8_t contents[];
}intset;
```

整数集合的每个元素都是 contents 数组的一个数据项，它们按照从小到大的顺序排列，并且不包含任何重复项。

length 属性记录了 contents 数组的大小。

需要注意的是虽然 contents 数组声明为 int8_t 类型，但是实际上contents 数组并不保存任何 int8_t 类型的值，其真正类型有 encoding 来决定。
**①、升级**

当我们新增的元素类型比原集合元素类型的长度要大时，需要对整数集合进行升级，才能将新元素放入整数集合中。具体步骤：

　　1、根据新元素类型，扩展整数集合底层数组的大小，并为新元素分配空间。

　　2、将底层数组现有的所有元素都转成与新元素相同类型的元素，并将转换后的元素放到正确的位置，放置过程中，维持整个元素顺序都是有序的。

　　3、将新元素添加到整数集合中（保证有序）。

升级能极大地节省内存。

**②、降级**

整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。

## 8.6 压缩列表

压缩列表（ziplist）是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。

**压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据按照一定规则编码在一块连续的内存区域，目的是节省内存。**

①、previous_entry_ength：记录压缩列表前一个字节的长度。previous_entry_ength的长度可能是1个字节或者是5个字节，如果上一个节点的长度小于254，则该节点只需要一个字节就可以表示前一个节点的长度了，如果前一个节点的长度大于等于254，则previous length的第一个字节为254，后面用四个字节表示当前节点前一个节点的长度。利用此原理即当前节点位置减去上一个节点的长度即得到上一个节点的起始位置，压缩列表可以从尾部向头部遍历。这么做很有效地减少了内存的浪费。

②、encoding：节点的encoding保存的是节点的content的内容类型以及长度，encoding类型一共有两种，一种字节数组一种是整数，encoding区域长度为1字节、2字节或者5字节长。

③、content：content区域用于保存节点的内容，节点内容类型和长度由encoding决定。

## 8.7 总结

大多数情况下，Redis使用简单字符串SDS作为字符串的表示，相对于C语言字符串，SDS具有常数复杂度获取字符串长度，杜绝了缓存区的溢出，减少了修改字符串长度时所需的内存重分配次数，以及二进制安全能存储各种类型的文件，并且还兼容部分C函数。

通过为链表设置不同类型的特定函数，Redis链表可以保存各种不同类型的值，除了用作列表键，还在发布与订阅、慢查询、监视器等方面发挥作用（后面会介绍）。

Redis的字典底层使用哈希表实现，每个字典通常有两个哈希表，一个平时使用，另一个用于rehash时使用，使用链地址法解决哈希冲突。

跳跃表通常是有序集合的底层实现之一，表中的节点按照分值大小进行排序。

整数集合是集合键的底层实现之一，底层由数组构成，升级特性能尽可能的节省内存。

压缩列表是Redis为节省内存而开发的顺序型数据结构，通常作为列表键和哈希键的底层实现之一。

# 9.各个对象类型对应的底层实现

## 9.1 字符串对象 String

- 字符串的编码可以是int、raw或embstr。
- 优先级：如果一个字符串的内容可以转换为long类型，那么该字符串就会被转换成long类型，Redis对象的ptr就会指向该long类型的对像，并且对象编码常量也用int。
- 而普通的字符串有2种，embstr或raw编码。如果字符串对象的长度小于等于32字节，就使用embstr编码。否则用传统的raw编码。
- embstr是一种短字符串的优化,其存储还是使用SDS结构,但raw编码会调用两次内存分配函数来分别创建redisObject结构和SDS结构,而embstr编码则通过调用一次内存分配函数来分配 一块连续的空间,空间中依次包含redisObject和SDS结构。

## 9.2 列表对象 List

- 列表对象的编码可以是ziplist或linkedlist。
- zpilist是压缩列表，需要使用连续的内存区域。当列表对象元素不多，元素体积不大时，Redis就采用ziplist存储。当数据量过大时，无法保证找到那么大的连续内存空间；而且插入的复杂度变为O(n)，每次插入都会重新realloc(动态内存调整，意思是当前内存无法存入更多数据时，申请分配新的连续内存)，而实际ziplist只需要一次malloc(动态内存分配，也就是初始化内存时分配一块合适的，此后不用再调整)。此时就使用linkedlist来存储对象，每当增加一个节点的时候，就需要重新malloc一块内存。

## 9.3 哈希对象 Hash

- 哈希对象的编码可以使用ziplist或hashtable。
- ziplist中的哈希对象按照key1，value1，key2，value2的顺序存放。当对象数目不多内容不大时，这种方式效率很高。
- ht是由dict结构来实现的

## 9.4 集合对象 Set

- 集合对象的编码可以是intset或者hashtable。只有当Set中的所有元素均为整数类型时才会使用intset。
- intset是一个整数集合，里面存的是某种同一类型的整数，支持如下3种长度的整数：



```c
#define INTSET_ENC_INT16 (sizeof(int16_t))
#define INTSET_ENC_INT32 (sizeof(int32_t))
#define INTSET_ENC_INT64 (sizeof(int64_t))
```

- intset是一个有序集合，查找元素的复杂度为O(logN)，但插入时不一定为O(logN)，因为有可能涉及到升级操作。比如当集合里全是int16_t型的整数，这时要插入一个int32_t，那么为了维持集合中数据类型的一致，那么所有的数据都会被转换成int32_t类型，涉及到内存的重新分配(realloc)，这时插入的复杂度就为O(N)了。intset不支持降级操作。

## 9.5 有序集合对象 ZSet

- 有序集合对象的编码可以是ziplist或者skiplist与hastable的结合。
- ziplist作为集合和作为哈希对象是一样的，不同的是哈希对象是key，value顺序存放，而有序集合是member和score顺序存放。按照score从小到大排序。
- skiplist是跳表，它实现了有序集合中的快速查找，大多数情况下它的查询速度可以和平衡树差不多。但是它实现比较简单，可以作为平衡树的替代品。
- 单一用hashtable，那可以快速查找、添加和删除元素，但没法保持集合的有序性。如果单一用skiplist，有序性可以得到保障，但查找的速度太慢O(logN)。