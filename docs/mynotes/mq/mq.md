# 1. 什么是消息队列

我们可以把消息队列看作是一个存放消息的容器，当我们需要使用消息的时候，直接从容器中取出消息供自己使用即可。

由于队列 Queue 是一种先进先出的数据结构，所以消费消息时也是按照顺序来消费的。

参与消息传递的双方称为 **生产者** 和 **消费者** ，生产者负责发送消息，消费者负责处理消息。

我们知道操作系统中的进程通信的一种很重要的方式就是消息队列。我们这里提到的消息队列稍微有点区别，
更多指的是各个服务以及系统内部各个组件/模块之前的通信，属于一种 **中间件** 。

维基百科是这样介绍中间件的：

> 中间件（英语：Middleware），又译中间件、中介层，是一类提供系统软件和应用软件之间连接、便于软件各部件之间的沟通的软件，应用软件可以借助中间件在不同的技术架构之间共享信息与资源。中间件位于客户机服务器的操作系统之上，管理着计算资源和网络通信。

简单来说：**中间件就是一类为应用软件服务的软件，应用软件是为用户服务的，用户不会接触或者使用到中间件。**

除了消息队列之外，常见的中间件还有 RPC 框架、分布式组件、HTTP 服务器、任务调度框架、配置中心、数据库层的分库分表工具和数据迁移工具等等。

# 2. 消息队列有什么用？

通常来说，使用消息队列能为我们的系统带来下面三点好处：

## 2.1 通过异步处理提高系统性能（减少响应所需时间
将用户的请求数据存储到消息队列之后就立即返回结果。随后，系统再对消息进行消费。因为用户请求数据写入消息队列之后就立即返回给用户了，但是请求数据在后续的业务校验、写数据库等操作中可能失败。

在我业务开发过程中，使用遇到过几个场景，一个是异步处理解析excel，比如供应商下采购单，他们习惯使用excel 批量上传要采购的sku，每个采购数据都要进行各种各样的校验，不能立即返回给用户，因此使用消息队列进行异步处理，将解析处理完成后的结果再展示给用户；另外一个是批量导出的场景；

因此，**使用消息队列进行异步处理之后，需要适当修改业务流程进行配合**，比如用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功，以免交易纠纷。这就类似我们平时手机订火车票和电影票。

## 2.2 **削峰/限流**

  **先将短时间高并发产生的事务消息存储在消息队列中，然后后端服务再慢慢根据自己的能力去消费这些消息，这样就避免直接把后端服务打垮掉。**

  举例：在电子商务一些秒杀、促销活动中，合理使用消息队列可以有效抵御促销活动刚开始大量订单涌入对系统的冲击。

## 2.3 **降低系统耦合性。**

使用消息队列还可以降低系统耦合性。我们知道如果模块之间不存在直接调用，那么新增模块或者修改模块就对其他模块影响较小，这样系统的可扩展性无疑更好一些。

生产者（客户端）发送消息到消息队列中去，接受者（服务端）处理消息，需要消费的系统直接去消息队列取消息进行消费即可而不需要和其他系统有耦合，这显然也提高了系统的扩展性。

**消息队列使用发布-订阅模式工作，消息发送者（生产者）发布消息，一个或多个消息接受者（消费者）订阅消息。** 从上图可以看到**消息发送者（生产者）和消息接受者（消费者）之间没有直接耦合**，消息发送者将消息发送至分布式消息队列即结束对消息的处理，消息接受者从分布式消息队列获取该消息后进行后续处理，并不需要知道该消息从何而来。**对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计**。

消息接受者对消息进行过滤、处理、包装后，构造成一个新的消息类型，将消息继续发送出去，等待其他消息接受者订阅该消息。因此基于事件（消息对象）驱动的业务架构可以是一系列流程。

另外，为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息生产者服务器上，等消息真正被消费者服务器处理后才删除消息。在消息队列服务器宕机后，生产者服务器会选择分布式消息队列服务器集群中的其他服务器发布消息。

**备注：** 不要认为消息队列只能利用发布-订阅模式工作，只不过在解耦这个特定业务环境下是使用发布-订阅模式的。除了发布-订阅模式，还有点对点订阅模式（一个消息只有一个消费者），我们比较常用的是发布-订阅模式。另外，这两种消息模型是 JMS 提供的，AMQP 协议还提供了另外 5 种消息模型。

## 2.4 **实现分布式事务**

我们知道分布式事务的解决方案之一就是 MQ 事务。

RocketMQ、 Kafka、Pulsar、QMQ 都提供了事务相关的功能。事务允许事件流应用将消费，处理，生产消息整个过程定义为一个原子操作。

如果在面试的时候你被面试官问到这个问题的话，一般情况是你在你的简历上涉及到消息队列这方面的内容，这个时候推荐你结合你自己的项目来回答。

# 3.使用消息队列会带来哪些问题？
- **系统可用性降低** <br>
系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了！

- **系统复杂性提高** <br>
加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！

- **一致性问题** <br>
我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!

# 4 JMS 和 AMQP

## 4.1 **JMS**

JMS（JAVA Message Service,java 消息服务）是 Java 的消息服务，JMS 的客户端之间可以通过 JMS 服务进行异步的消息传输。**JMS（JAVA Message Service，Java 消息服务）API 是一个消息服务的标准或者说是规范**，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。

JMS 定义了五种不同的消息正文格式以及调用的消息类型，允许你发送并接收以一些不同形式的数据：

- `StreamMessage：Java` 原始值的数据流
- `MapMessage`：一套名称-值对
- `TextMessage`：一个字符串对象
- `ObjectMessage`：一个序列化的 Java 对象
- `BytesMessage`：一个字节的数据流

ActiveMQ（已被淘汰） 就是基于 JMS 规范实现的

JMS有两种消息模型：

- 点到点（P2P）模型

  使用**队列（Queue）\**作为消息通信载体；满足\**生产者与消费者模式**，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。比如：我们生产者发送 100 条消息的话，两个消费者来消费一般情况下两个消费者会按照消息发送的顺序各自消费一半（也就是你一个我一个的消费。）

- 发布/订阅（Pub/Sub）模型

  发布订阅模型（Pub/Sub） 使用**主题（Topic）\**作为消息通信载体，类似于\**广播模式**；发布者发布一条消息，该消息通过主题传递给所有的订阅者，**在一条消息广播之后才订阅的用户则是收不到该条消息的**。



## 4.2 **AMQP**

AMQP，即 Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准 **高级消息队列协议**（二进制应用层协议），是应用层协议的一个开放标准，为面向消息的中间件设计，兼容 JMS。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品，不同的开发语言等条件的限制。RabbitMQ 就是基于 AMQP 协议实现的。



## 4.3 **总结：**

- AMQP 为消息定义了线路层（wire-level protocol）的协议，而 JMS 所定义的是 API 规范。在 Java 体系中，多个 client 均可以通过 JMS 进行交互，不需要应用修改代码，但是其对跨平台的支持较差。而 AMQP 天然具有跨平台、跨语言特性。
- JMS 支持 `TextMessage`、`MapMessage` 等复杂的消息类型；而 AMQP 仅支持 `byte[]` 消息类型（复杂的类型可序列化后发送）。
- 由于 Exchange 提供的路由算法，AMQP 可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持 队列 和 主题/订阅 方式两种。

# 5. RPC 和消息队列的区别

RPC 和消息队列都是分布式微服务系统中重要的组件之一，下面我们来简单对比一下两者：

- **从用途来看**：RPC 主要用来解决两个服务的远程通信问题，不需要了解底层网络的通信机制。通过 RPC 可以帮助我们调用远程计算机上某个服务的方法，这个过程就像调用本地方法一样简单。消息队列主要用来降低系统耦合性、实现任务异步、有效地进行流量削峰。

- **从通信方式来看**：RPC 是双向直接网络通讯，消息队列是单向引入中间载体的网络通讯。

- **从架构上来看**：消息队列需要把消息存储起来，RPC 则没有这个要求，因为前面也说了 RPC 是双向直接网络通讯。

- **从请求处理的时效性来看**：通过 RPC 发出的调用一般会立即被处理，存放在消息队列中的消息并不一定会立即被处理。

  RPC 和消息队列本质上是网络通讯的两种不同的实现机制，两者的用途不同，万不可将两者混为一谈。

# 6. 分布式消息队列技术选型

常见的消息队列有哪些？

## 6.1 **Kafka**
Kafka 是 LinkedIn 开源的一个分布式流式处理平台，已经成为 Apache 顶级项目，早期被用来用于处理海量的日志，后面才慢慢发展成了一款功能全面的高性能消息队列。

流式处理平台具有三个关键功能：

1. **消息队列**：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。
2. **容错的持久方式存储记录消息流**：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。
3. **流式处理平台：** 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。

Kafka 是一个分布式系统，由通过高性能 TCP 网络协议进行通信的服务器和客户端组成，可以部署在在本地和云环境中的裸机硬件、虚拟机和容器上。

在 Kafka 2.8 之前，Kafka 最被大家诟病的就是其重度依赖于 Zookeeper 做元数据管理和集群的高可用。在 Kafka 2.8 之后，引入了基于 Raft 协议的 KRaft 模式，不再依赖 Zookeeper，大大简化了 Kafka 的架构，让你可以以一种轻量级的方式来使用 Kafka。

不过，要提示一下：**如果要使用 KRaft 模式的话，建议选择较高版本的 Kafka，因为这个功能还在持续完善优化中。Kafka 3.3.1 版本是第一个将 KRaft（Kafka Raft）共识协议标记为生产就绪的版本。**

------

## 6.2 **RocketMQ**

RocketMQ 是阿里开源的一款云原生“消息、事件、流”实时数据处理平台，借鉴了 Kafka，已经成为 Apache 顶级项目。

RocketMQ 的核心特性（摘自 RocketMQ 官网）：

- 云原生：生与云，长与云，无限弹性扩缩，K8s 友好
- 高吞吐：万亿级吞吐保证，同时满足微服务与大数据场景。
- 流处理：提供轻量、高扩展、高性能和丰富功能的流计算引擎。
- 金融级：金融级的稳定性，广泛用于交易核心链路。
- 架构极简：零外部依赖，Shared-nothing 架构。
- 生态友好：无缝对接微服务、实时计算、数据湖等周边生态。

根据官网介绍：

> Apache RocketMQ 自诞生以来，因其架构简单、业务功能丰富、具备极强可扩展性等特点被众多企业开发者以及云厂商广泛采用。历经十余年的大规模场景打磨，RocketMQ 已经成为业内共识的金融级可靠业务消息首选方案，被广泛应用于互联网、大数据、移动互联网、物联网等领域的业务场景。

------

## 6.3 **RabbitMQ**

RabbitMQ 是采用 Erlang 语言实现 AMQP(Advanced Message Queuing Protocol，高级消息队列协议）的消息中间件，它最初起源于金融系统，用于在分布式系统中存储转发消息。

RabbitMQ 发展到今天，被越来越多的人认可，这和它在易用性、扩展性、可靠性和高可用性等方面的卓著表现是分不开的。RabbitMQ 的具体特点可以概括为以下几点：

- **可靠性：** RabbitMQ 使用一些机制来保证消息的可靠性，如持久化、传输确认及发布确认等。
- **灵活的路由：** 在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能，RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个交换器绑定在一起，也可以通过插件机制来实现自己的交换器。这个后面会在我们讲 RabbitMQ 核心概念的时候详细介绍到。
- **扩展性：** 多个 RabbitMQ 节点可以组成一个集群，也可以根据实际业务情况动态地扩展集群中节点。
- **高可用性：** 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队列仍然可用。
- **支持多种协议：** RabbitMQ 除了原生支持 AMQP 协议，还支持 STOMP、MQTT 等多种消息中间件协议。
- **多语言客户端：** RabbitMQ 几乎支持所有常用语言，比如 Java、Python、Ruby、PHP、C#、JavaScript 等。
- **易用的管理界面：** RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集群中的节点等。在安装 RabbitMQ 的时候会介绍到，安装好 RabbitMQ 就自带管理界面。
- **插件机制：** RabbitMQ 提供了许多插件，以实现从多方面进行扩展，当然也可以编写自己的插件。感觉这个有点类似 Dubbo 的 SPI 机制

-----

## 6.4 **Pulsar**

Pulsar 是下一代云原生分布式消息流平台，最初由 Yahoo 开发 ，已经成为 Apache 顶级项目。

Pulsar 集消息、存储、轻量化函数式计算为一体，采用计算与存储分离架构设计，支持多租户、持久化存储、多机房跨区域数据复制，具有强一致性、高吞吐、低延时及高可扩展性等流数据存储特性，被看作是云原生时代实时消息流传输、存储和计算最佳解决方案。

Pulsar 的关键特性如下（摘自官网）：

- 是下一代云原生分布式消息流平台。
- Pulsar 的单个实例原生支持多个集群，可跨机房在集群间无缝地完成消息复制。
- 极低的发布延迟和端到端延迟。
- 可无缝扩展到超过一百万个 topic。
- 简单的客户端 API，支持 Java、Go、Python 和 C++。
- 主题的多种订阅模式（独占、共享和故障转移）。
- 通过 Apache BookKeeper 提供的持久化消息存储机制保证消息传递 。
- 由轻量级的 serverless 计算框架 Pulsar Functions 实现流原生的数据处理。
- 基于 Pulsar Functions 的 serverless connector 框架 Pulsar IO 使得数据更易移入、移出 Apache Pulsar。
- 分层式存储可在数据陈旧时，将数据从热存储卸载到冷/长期存储（如 S3、GCS）中。

-----

如何选择？

> 参考《Java 工程师面试突击第 1 季-中华石杉老师》

| 对比方向 | 概要                                                         |
| -------- | ------------------------------------------------------------ |
| 吞吐量   | 万级的 ActiveMQ 和 RabbitMQ 的吞吐量（ActiveMQ 的性能最差）要比十万级甚至是百万级的 RocketMQ 和 Kafka 低一个数量级。 |
| 可用性   | 都可以实现高可用。ActiveMQ 和 RabbitMQ 都是基于主从架构实现高可用性。RocketMQ 基于分布式架构。 Kafka 也是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 时效性   | RabbitMQ 基于 Erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级，其他几个都是 ms 级。 |
| 功能支持 | Pulsar 的功能更全面，支持多租户、多种消费模式和持久性模式等功能，是下一代云原生分布式消息流平台。 |
| 消息丢失 | ActiveMQ 和 RabbitMQ 丢失的可能性非常低， Kafka、RocketMQ 和 Pulsar 理论上可以做到 0 丢失。 |

## 6.5 **总结：**

- ActiveMQ 的社区算是比较成熟，但是较目前来说，ActiveMQ 的性能比较差，而且版本迭代很慢，不推荐使用，已经被淘汰了。
- RabbitMQ 在吞吐量方面虽然稍逊于 Kafka、RocketMQ 和 Pulsar，但是由于它基于 Erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级。但是也因为 RabbitMQ 基于 Erlang 开发，所以国内很少有公司有实力做 Erlang 源码级别的研究和定制。如果业务场景对并发量要求不是太高（十万级、百万级），那这几种消息队列中，RabbitMQ 或许是你的首选。
- RocketMQ 和 Pulsar 支持强一致性，对消息一致性要求比较高的场景可以使用。
- RocketMQ 阿里出品，Java 系开源项目，源代码我们可以直接阅读，然后可以定制自己公司的 MQ，并且 RocketMQ 有阿里巴巴的实际业务场景的实战考验。
- Kafka 的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms 级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展。同时 Kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。Kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略这个特性天然适合大数据实时计算以及日志收集。如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。

# 7 消息队列的投递语义
在分布式系统中使用网络进行通信确实是一种不可靠的方式，消息的发送者只能知道掌控当前节点，所以没有办法保证传输渠道的可靠性，网络超时这种常见的通信错误极大地增加了分布式系统通信的复杂度，我们可以对网络提供的基本传输能力进行封装，保证数据通信的可靠性。

网络请求由于超时的问题，消息的发送者只能通过重试的方式对消息进行重发，但是这就可能会导致消息的重复发送与处理，然而如果超时后不重新发送消息也可能导致消息的丢失，所以如何在不可靠的通信方式中，保证消息不重不漏是非常关键的。

我们一般都会认为，消息的投递语义有三种，分别是最多一次（At-Most Once）、至少一次（At-Least Once）以及精确一次（Exactly Once）。

## 7.1 最多一次（At-most-once)
最多一次其实非常容易保证的，UDP 这种传输层的协议其实保证的就是最多一次消息投递，消息的发送者只会尝试发送该消息一次，并不会关心该消息是否得到了远程节点的响应。

无论该请求是否发送给了接受者，发送者都不会重新发送这条消息；这其实就是最最基本的消息投递语义，然而消息可能由于网络或者节点的故障出现丢失。

这本质上是一种尽力而为的方法。

## 7.2 至少一次（At-least-once）
为了解决最多一次时的消息丢失问题，消息的发送者需要在网络出现超时重新发送相同的消息，也就是引入超时重试的机制，在发送者发出消息会监听消息的响应，如果超过了一定时间也没有得到响应就会重新发送该消息，直到得到确定的响应结果。

对于最少一次的投递语义，我们不仅需要引入超时重试机制，还需要关心每一次请求的响应，只有这样才能确保消息不会丢失，但是却可能会造成消息的重复，这就是最少一次在解决消息丢失后引入的新问题。

## 7.3 精确一次（Exactly-once）
虽然最少一次解决了最多一次的消息丢失问题，但是由于重试却带来了另一个问题 - 消息重复，也就是接受者可能会多次收到同一条消息；从理论上来说，在分布式系统中想要解决消息重复的问题是不可能的，很多消息服务提供了正好一次的 QoS 其实是在接收端进行了去重。

消息去重需要生产者生产消息时加入去重的 key，消费者可以通过唯一的 key 来判断当前消息是否是重复消息，从消息发送者的角度来看，实现正好一次的投递是不可能的，但是从整体来看，我们可以通过唯一 key 或者重入幂等的方式对消息进行『去重』。

消息的重复是不可能避免的，除非我们允许消息的丢失，然而相比于丢失消息，重复发送消息其实是一种更能让人接受的处理方式，因为一旦消息丢失就无法找回，但是消息重复却可以通过其他方法来避免副作用。

# 8. xx供应链的消息队列选型

在xx的时候我们使用到的MQ 就只有两个，一个是RabbitMQ,另外一个是Kafka,这两个是两种完全不同类型的MQ，RabbitMQ面向的是单条消息处理，是一种传统的MQ，Kafka面向的是消息批处理，是一种面向大数据处理的消息队列

在使用RabbitMQ时，我们的技术栈是celery + rabbit mq
在使用kafka 时，我们的技术栈是自行改版的saturn + kafka

---

## 8.1 RabbitMQ使用
在早期的pms 和后面的fms 中，为了业务快速发展都是选择了用django 这个python框架去做开发，所以也为了开发速度就选了celery（django-celery）去做消息队列，所以rabbitmq 的选型是：

**确定使用django --选型--> django-celery --选型--> rabbit mq**

一切都是为了快速开发，但是这种开发模式后期遇到了几个问题：
1. xxx 团队层面为了方便后续整体开发效率，打算统一技术栈，并最终决定在MQ 上统一到Kafka去；
2. RabbitMQ 上我们了解很少，也没有专业的运维维护，所以无法保证他的稳定性以及问题排查；

这个可以举两个例子来说明下：
- 无法保证稳定性：在23年2月底的一个周日下午17点的时候，由于RabbitMQ集群中某个节点硬盘突然损坏了，然后该节点对写入无响应，导致线上发生大量接口超时现象（python 代码中是同步发布的，并且未设置超时时间）。最后该问题再7分钟后自动恢复（RabbitMQ集群踢出了坏掉的节点，并且自动切到备用节点去）。在这段时间内所有设计RabbitMQ publish 的接口全部超时，并且从运维侧做不到快速恢复或者人工干预；
- 对Rabbit MQ的不了解：在22年7月7日的大促中，发生了线上接口RT 逐渐变高，并且一直持续，在几十分钟后导致线上接口不可用的问题，（单次rabbitmq publish的RT 从几毫秒上升到了分钟级别），并且重启pod 只能“非常短暂地”缓解这个现象（也就几十秒就恢复到分钟级别的情况）。当时二十多个人（开发、运维等）排查了一晚上都没查到根因，导致了一整个晚上服务不可用（17点开始，凌晨1点才恢复），第二天早上才查到根因是什么，中途还进行了多次变更尝试，其中甚至包括了错误尝试（缩容消费者）

这件事情的根本原因是这样的：<br>
有一个消息队列（FO那边的tracking）的发布很快很多，但是消费很慢，因为tracking 在当时只是一个记录而已，所以没有人关心它的消费速度，它也就慢慢堆积到一百多万的地步，然后，rabbitmq 里面其实有一个自作主张的限流策略，在消息产生堆积的时候，为了保护自己，他会直接去限流，并且这个限流策略跟它自己的资源占用无关，就只是一个打分的策略，导致最后FO 那边发布太快，导致限流后，引发整体应用崩盘，当时的场景：
- 各个团队的项目都在fms 项目里面；
- django-celery 的连接是公用的
**producer --被迫block--> connection --被迫block--> channel--被迫block--> exchanger  --block--> tracking**

所以导致所有的连接都卡在发布tracking 的这个队列的操作上，其他pubulish 操作无法获取到连接。<br>
当时大家也全都猜错方向了：<br>
运维说rabbitmq 集群监控正常，DB、 CPU、 内存，网络状态都十分良好；<br>
开发一开始猜测是消费太快导致处理不过来，于是缩容消费者，后面看来这个完全是放大了问题；<br>
而最后的解决方案是临时修改线上代码，把tracking 移走。<br>

----

## 8.2 Kafka使用

xxx 使用Kafka是配合着Saturn 一起使用的，主要场景：
- 业务单条消息消费，如异步逻辑处理之类的；
- 异构平台数据同步，从MySQL同步到ES；
- Data平台数据同步，业务信息同步到Hive、Clickhouse

其中核心消费方式是方式业务单条消息消费,然后整体要求使用供应链自己魔改过的Saturn 进行消费。

Saturn整体消费Kafka的逻辑是：<br>
使用SideCar 模式，在构建是把executor 和业务逻辑打包到同一个pod 里面，然后pod 里面启动executor 进程和业务进程，executor 进程启动后会向Sturn Server同步配置，然后根据拉取到的配置去连接Kafka, 接着对收到的每一条消息都本地调用业务进程进行消费
- 如何单条消息地消费？（幂等性，每条消息只被消费一次，rabbit mq 的逻辑，kafka通过逻辑方式实现）<br>
Saturn Executor内部每次拉取一批消息后，会在本生成一个slot 列表，代表不同的ID 对应的消息是否已经被消费，然后会按照已经全部消费的最大ID 去commit;

- 如何保证事务性？<br>
Saturn 每个消息处理会返回一个错误，当处理逻辑返回错误时会进入重试逻辑，重试方式包括： 
不重试； <br>
按照指定时间间隔本地重试，由业务进程对应的SDK 来重试，重试完成后才真正返回reply 给executor; <br>
重发消息，并按照指定时间间隔延时重试，利用redis 和kafka实现，消息先存到redis 里，到了对应的时间再发送到Kafka里面 <br>

- SideCar模式的优缺点是什么？<br>
将应用程序的功能划分为单独的进程，即 `Sidecar` 模式。`Sidecar` 译为摩托车的边车，用到软件架构中，
`Sidecar` 模式指在原来的业务逻辑上再新加一个抽象层。`Sidecar` 模式是一种更具动态性的方法，其作为一种模式并不是的正式约定。它将应用程序的功能划分为单独的进程，运行在同一个 pod 中，`Sidecar` 模式允许在应用程序旁边添加功能，而无需修改应用程序代码。
在 `Sidecar` 部署方式中，每个应用的容器旁都会部署一个或者多个伴生容器，多个容器共享存储、网络等资源。具体优势有：
将不同的功能抽象到不同的层来降低微服务的代码复杂性。
每个 `Sidecar` 可以独立升级更新。
分离业务无关功能（例如：配置文件获取），提升代码重用度。
不再需要编写相同的第三方组件配置文件和代码，能够降低代码重复度。
就像软件架构中的所有东西一样，也是有取舍的。因此，sidecar 肯定有缺点。让我们来看看其中的一些：

- 如果不在K8s中，就会有更多的部署复杂性（EC2）。
- 需要有很好的可观察性，否则 sidecar 会变成黑盒子。
- 难以对应用进行调试。比方说，sidecar 是用RUST写的，而应用程序是用Java或Go写的。
- 可靠性路径： sidecar 现在成为可靠性路径的一部分。这意味着停机时间可能是一个大问题。


- 使用Saturn 时有遇到什么问题？
  1）saturn 自身没有维护好，一些地方有bug,导致业务需要自身兼容，比如上面说到的重试是可以指定上限的，但是有个版本的saturn 存在问题，使用重发消息的方式时会无限重试；
  2）性能消耗过大，在简单逻辑中（比如99%的情况都是简单消息解析并逻辑判断），使用saturn 来消费，比直接使用原生SDK 消费（kafka-go）性能消耗高30倍，原因是saturn 是sidecar 模式，使用Java 编写，且每次消费都是一次RPC请求；
  3）这个跟上一点有关，单pod 内不能过高并发，Pod 内需要启动SaturnExecutor ,且该进程资源消耗过大，在高并发时，Saturn Executor自身资源占用很高（先是高内存占用，然后导致频繁GC，进而导致高CPU 占用），按照标准来说，95%的消息都是简单逻辑过滤的情况下，在1000qps时，最低要求16GB，8Core,如果使用原生的SDK 的话，这个消耗可以降低到 4GB 2Core.

- 至于为什么还要用？
  定时任务也用，统一到一起的话，在基础开发上好管理；
  统一技术栈，供应链基于这些统一技术栈开发了很多功能，比如流量回放，影子流量等等；
  可以基于Server随时管理，修改配置、启动、暂停等

----

总结：最终选型为Kafka + Saturn而不是RabbitMQ的原因为，1）功能上，Kafka 可以使用逻辑方式来实现单个消息消费以替代rabbitmq , 而rabbitmq 无法用于实现大批量数据消费（大数据同步）； 2）可维护性上：Kafka 是xx在维护，是公司级别的组件，rabbitmq 只有供应链自己维护，只是一个部门级别的组件，虽然后续整体交给了infra,但是整体层面上还是非核心基建。
