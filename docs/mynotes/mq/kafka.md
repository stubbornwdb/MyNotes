# 1.kafka 基础


# 2.kafka 常见问题





# 2 Kafka

## 2.1 Kafka 是什么？主要应用场景有哪些？

Kafka 是一个分布式流式处理平台。这到底是什么意思呢？

流平台具有三个关键功能：

1. **消息队列**：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。
2. **容错的持久方式存储记录消息流**：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。
3. **流式处理平台：** 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。

Kafka 主要有两大应用场景：

1. **消息队列**：建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。
2. **数据处理：** 构建实时的流数据处理程序来转换或处理数据流。



## 2.2 和其他消息队列相比,Kafka 的优势在哪里？

我们现在经常提到 Kafka 的时候就已经默认它是一个非常优秀的消息队列了，我们也会经常拿它跟 RocketMQ、RabbitMQ 对比。我觉得 Kafka 相比其他消息队列主要的优势如下：

1. **极致的性能**：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
2. **生态系统兼容性无可匹敌**：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

实际上在早期的时候 Kafka 并不是一个合格的消息队列，早期的 Kafka 在消息队列领域就像是一个衣衫褴褛的孩子一样，功能不完备并且有一些小问题比如丢失消息、不保证消息可靠性等等。当然，这也和 LinkedIn 最早开发 Kafka 用于处理海量的日志有很大关系，哈哈哈，人家本来最开始就不是为了作为消息队列滴，谁知道后面误打误撞在消息队列领域占据了一席之地。

随着后续的发展，这些短板都被 Kafka 逐步修复完善。所以，**Kafka 作为消息队列不可靠这个说法已经过时！**

## 2.3 队列模型了解吗？Kafka 的消息模型知道吗？

**队列模型：早期的消息模型**

**使用队列（Queue）作为消息通信载体，满足生产者与消费者模式，一条消息只能被一个消费者使用，未被消费的消息在队列中保留直到被消费或超时。** 比如：我们生产者发送 100 条消息的话，两个消费者来消费一般情况下两个消费者会按照消息发送的顺序各自消费一半（也就是你一个我一个的消费。）

**队列模型存在的问题：**

假如我们存在这样一种情况：我们需要将生产者产生的消息分发给多个消费者，并且每个消费者都能接收到完整的消息内容。

这种情况，队列模型就不好解决了。很多比较杠精的人就说：我们可以为每个消费者创建一个单独的队列，让生产者发送多份。这是一种非常愚蠢的做法，浪费资源不说，还违背了使用消息队列的目的。



**发布-订阅模型:Kafka 消息模型**

发布-订阅模型主要是为了解决队列模型存在的问题。

发布订阅模型（Pub-Sub） 使用**主题（Topic）** 作为消息通信载体，类似于**广播模式**；发布者发布一条消息，该消息通过主题传递给所有的订阅者，**在一条消息广播之后才订阅的用户则是收不到该条消息的**。

**在发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。**

**Kafka 采用的就是发布 - 订阅模型。**

> **RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。**



## 2.4 Kafka的设计
Kafka 将消息以 topic 为单位进行归纳，发布消息的程序称为 Producer，消费消息的程序称为 Consumer。它是以集群的方式运行，可以由一个或多个服务组成，每个服务叫做一个 Broker，Producer 通过网络将消息发送到 kafka 集群，集群向消费者提供消息，broker 在中间起到一个代理保存消息的中转站。

Kafka 中重要的组件
1）Producer：消息生产者，发布消息到Kafka集群的终端或服务
2）Broker：一个 Kafka 节点就是一个 Broker，多个Broker可组成一个Kafka 集群。

如果某个 Topic 下有 n 个Partition 且集群有 n 个Broker，那么每个 Broker会存储该 Topic 下的一个 Partition

如果某个 Topic 下有 n 个Partition 且集群中有 m+n 个Broker，那么只有 n 个Broker会存储该Topic下的一个 Partition

如果某个 Topic 下有 n 个Partition 且集群中的Broker数量小于 n，那么一个 Broker 会存储该 Topic 下的一个或多个 Partition，这种情况尽量避免，会导致集群数据不均衡

3）Topic：消息主题，每条发布到Kafka集群的消息都会归集于此，Kafka是面向Topic 的；Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。

4）Partition：Partition 是Topic在物理上的分区，Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。一个Topic可以分为多个Partition，每个Partition是一个有序的不可变的记录序列。单一主题中的分区有序，但无法保证主题中所有分区的消息有序。

5）Consumer：从Kafka集群中消费消息的终端或服务

6）Consumer Group：每个Consumer都属于一个Consumer Group，每条消息只能被Consumer Group中的一个Consumer消费，但可以被多个Consumer Group消费。

7）Replica：Partition 的副本，用来保障Partition的高可用性。

8）Controller： Kafka 集群中的其中一个服务器，用来进行Leader election以及各种 Failover 操作。

9）Zookeeper：Kafka 通过Zookeeper来存储集群中的 meta 消息



## 2.5 Kafka 的多副本机制了解吗？带来了什么好处？

还有一点我觉得比较重要的是 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

> 生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。

**Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？**

1. Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。
2. Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。



## 2.6 Zookeeper 在 Kafka 中的作用知道吗？

> **要想搞懂 zookeeper 在 Kafka 中的作用 一定要自己搭建一个 Kafka 环境然后自己进 zookeeper 去看一下有哪些文件夹和 Kafka 有关，每个节点又保存了什么信息。** 一定不要光看不实践，这样学来的也终会忘记！这部分内容参考和借鉴了这篇文章：https://www.jianshu.com/p/a036405f989c 。

ZooKeeper 主要为 Kafka 提供元数据的管理的功能。

从图中我们可以看出，Zookeeper 主要为 Kafka 做了下面这些事情：

1. **Broker 注册**：在 Zookeeper 上会有一个专门**用来进行 Broker 服务器列表记录**的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到 `/brokers/ids` 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去
2. **Topic 注册**：在 Kafka 中，同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：`/brokers/topics/my-topic/Partitions/0`、`/brokers/topics/my-topic/Partitions/1`
3. **负载均衡**：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。



## 2.7 Kafka 如何保证消息的消费顺序？

我们在使用消息队列的过程中经常有业务场景需要严格保证消息的消费顺序，比如我们同时发了 2 个消息，这 2 个消息对应的操作分别对应的数据库操作是：

1. 更改用户会员等级。
2. 根据会员等级计算订单价格。

假如这两条消息的消费顺序不一样造成的最终结果就会截然不同。

我们知道 Kafka 中 Partition(分区)是真正保存消息的地方，我们发送的消息都被放在了这里。而我们的 Partition(分区) 又存在于 Topic(主题) 这个概念中，并且我们可以给特定 Topic 指定多个 Partition。

每次添加消息到 Partition(分区) 的时候都会采用尾加法，如上图所示。 **Kafka 只能为我们保证 Partition(分区) 中的消息有序。**

> 消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。

所以，我们就有一种很简单的保证消息消费顺序的方法：**1 个 Topic 只对应一个 Partition**。这样当然可以解决问题，但是破坏了 Kafka 的设计初衷。

Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key 。

总结一下，对于如何保证 Kafka 中消息消费的顺序，有了下面两种方法：

1. 1 个 Topic 只对应一个 Partition。
2. （推荐）发送消息的时候指定 key/Partition。

当然不仅仅只有上面两种方法，上面两种方法是我觉得比较好理解的



## 2.8 Kafka 如何保证消息不丢失

- **生产者丢失消息的情况**

生产者(Producer) 调用`send`方法发送消息之后，消息可能因为网络问题并没有发送过去。

所以，我们不能默认在调用`send`方法发送消息之后消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是 Kafka 生产者(Producer) 使用 `send` 方法发送消息实际上是异步的操作，我们可以通过 `get()`方法获取调用结果，但是这样也让它变为了同步操作，示例代码如下：

> **详细代码见我的这篇文章：[Kafka 系列第三篇！10 分钟学会如何在 Spring Boot 程序中使用 Kafka 作为消息队列?open in new window](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247486269&idx=2&sn=ec00417ad641dd8c3d145d74cafa09ce&chksm=cea244f6f9d5cde0c8eb233fcc4cf82e11acd06446719a7af55230649863a3ddd95f78d111de&token=1633957262&lang=zh_CN#rd)**

```java
SendResult<String, Object> sendResult = kafkaTemplate.send(topic, o).get();
if (sendResult.getRecordMetadata() != null) {
  logger.info("生产者成功发送消息到" + sendResult.getProducerRecord().topic() + "-> " + sendRe
              sult.getProducerRecord().value().toString());
}
```

但是一般不推荐这么做！可以采用为其添加回调函数的形式，示例代码如下：

```java
        ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, o);
        future.addCallback(result -> logger.info("生产者成功发送消息到topic:{} partition:{}的消息", result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),
                ex -> logger.error("生产者发送消失败，原因：{}", ex.getMessage()));
```

如果消息发送失败的话，我们检查失败的原因之后重新发送即可！

**另外这里推荐为 Producer 的`retries `（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你 3 次一下子就重试完了**

- **消费者丢失消息的情况**

我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。

**解决办法也比较粗暴，我们手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。** 但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。

- **Kafka 弄丢了消息**

我们知道 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。

**试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。**

**设置 acks = all**

解决办法就是我们设置 **acks = all**。acks 是 Kafka 生产者(Producer) 很重要的一个参数。

acks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 **acks = all** 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高.

**设置 replication.factor >= 3**

为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 **replication.factor >= 3**。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。

**设置 min.insync.replicas > 1**

一般情况下我们还需要设置 **min.insync.replicas> 1** ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。**min.insync.replicas** 的默认值为 1 ，在实际生产中应尽量避免默认值 1。

但是，为了保证整个 Kafka 服务的高可用性，你需要确保 **replication.factor > min.insync.replicas** 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 **replication.factor = min.insync.replicas + 1**。

**设置 unclean.leader.election.enable = false**

> **Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false**

我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 **unclean.leader.election.enable = false** 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。

## 2.9 Kafka 如何保证消息不重复消费

**kafka 出现消息重复消费的原因：**

- 服务端侧已经消费的数据没有成功提交 offset（根本原因）。
- Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。

**解决方案：**

- 消费消息服务做幂等校验，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。

- 将

  `enable.auto.commit`

  参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：

  什么时候提交 offset 合适？

    - 处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样
    - 拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。

## 2.10 Kafka 性能高的原因
- 利用了 PageCache 缓存

- 磁盘顺序写
  Kafka 的存储和检索机制采用了一种基于顺序读写的方式，可以实现高效的数据存储和检索。具体来说，Kafka 将每个分区的数据以追加的方式写入到磁盘文件中，并按照消息的时间戳进行索引。这样可以快速地定位和读取指定时间范围内的消息，从而提高数据的检索效率。

- 零拷贝技术
  Kafka 采用了零拷贝技术，避免了数据在内存和网络之间的多次复制，从而提高了数据传输的效率。具体来说，Kafka 的 Producer 和 Consumer 在发送和接收消息时，可以直接操作内存中的数据，而无需将数据复制到操作系统内核缓冲区中。这种零拷贝技术可以大大减少数据传输的时间和资源消耗。

- pull 拉模式
  在 pull 模式中，Kafka 的 Consumer 可以自主控制消息的获取速度和频率，可以根据自身的处理能力和需求来决定何时获取消息以及获取多少消息。这样就可以避免 Consumer 被消息的高速流入所压垮，从而提高了整个系统的吞吐量和稳定性。
  消息的批量获取
  Kafka 的 pull 模式支持批量获取消息，可以在一次请求中获取多条消息。这样可以减少网络传输的次数，提高了数据传输的效率。
  消息的按需获取
  在 pull 模式中，Kafka 的 Consumer 可以按需获取消息，即只获取自己需要的消息。这样可以减少网络传输的数据量，提高了数据传输的效率。

- 批量发送（Batching）和压缩
  Kafka 允许 Producer 将多条消息一起批量发送到 Broker。这种批量发送可以减少网络传输的次数，从而提高传输效率。同时，Kafka 还支持 Gzip、Snappy 等多种压缩算法，可以将消息压缩后再发送，从而进一步减少网络传输的数据量，提高传输效率。

## 2.11 Kafka 文件高效存储设计原理
Kafka把Topic中一个Partition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完成的文件，减少磁盘占用
通过索引信息可以快速定位Message和确定response的最大大小
通过将索引元数据全部映射到 memory，可以避免 Segment 文件的磁盘I/O操作
通过索引文件稀疏存储，可以大幅降低索引文件元数据占用空间大小

## 2.12 Kafka的优缺点
优点
高性能、高吞吐量、低延迟：Kafka 生产和消费消息的速度都达到每秒10万级
高可用：所有消息持久化存储到磁盘，并支持数据备份防止数据丢失
高并发：支持数千个客户端同时读写
容错性：允许集群中节点失败（若副本数量为n，则允许 n-1 个节点失败）
高扩展性：Kafka 集群支持热伸缩，无须停机

缺点
没有完整的监控工具集
不支持通配符主题选择

## 2.13 Kafka 的应用场景
日志聚合：可收集各种服务的日志写入kafka的消息队列进行存储
消息系统：广泛用于消息中间件
系统解耦：在重要操作完成后，发送消息，由别的服务系统来完成其他操作
流量削峰：一般用于秒杀或抢购活动中，来缓冲网站短时间内高流量带来的压力
异步处理：通过异步处理机制，可以把一个消息放入队列中，但不立即处理它，在需要的时候再进行处理

## 2.14 Kafka 中生产者运行流程
一条消息发过来首先会被封装成一个 ProducerRecord 对象
对该对象进行序列化处理（可以使用默认，也可以自定义序列化）
对消息进行分区处理，分区的时候需要获取集群的元数据，决定这个消息会被发送到哪个主题的哪个分区
分好区的消息不会直接发送到服务端，而是放入生产者的缓存区，多条消息会被封装成一个批次（Batch），默认一个批次的大小是 16KB
Sender 线程启动以后会从缓存里面去获取可以发送的批次
Sender 线程把一个一个批次发送到服务端

## 2.15 Kafka中消息的消费模式
Kafka采用大部分消息系统遵循的传统模式：Producer将消息推送到Broker，Consumer从Broker获取消息。

如果采用 Push 模式，则Consumer难以处理不同速率的上游推送消息。

采用 Pull 模式的好处是Consumer可以自主决定是否批量的从Broker拉取数据。Pull模式有个缺点是，如果Broker没有可供消费的消息，
将导致Consumer不断在循环中轮询，直到新消息到达。为了避免这点，Kafka有个参数可以让Consumer阻塞直到新消息到达。

## 2.16 Kafka Rebalance
同一个 consumer 消费者组 group.id 中，新增了消费者进来，会执行 Rebalance 操作
消费者离开当期所属的 consumer group组。比如宕机
分区数量发生变化时(即 topic 的分区数量发生变化时)
消费者主动取消订阅
Rebalance的过程如下：

第一步：所有成员都向coordinator发送请求，请求入组。一旦所有成员都发送了请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader。

第二步：leader开始分配消费方案，指明具体哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案发给coordinator。coordinator接收到分配方案之后会把方案发给各个consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。

所以对于Rebalance来说，Coordinator起着至关重要的作用

## 2.17 Kafka 串讲
面试官：今天要不来聊聊消息队列吧？我看你项目不少地方都写到Kafka了

候选者：嗯嗯

面试官：那你简单说明下你使用Kafka的场景吧

候选者：使用消息队列的目的总的来说可以有三种情况：解耦、异步和削峰

候选者：比如举我项目的例子吧，我现在维护一个消息管理平台系统，对外提供接口给各个业务方调用

候选者：他们调用接口之后，实际上『不是同步』下发了消息。

候选者：在接口处理层只是把该条消息放到了消息队列上，随后就直接返回结果给接口调用者了。

候选者：这样的好处就是：

候选者：1. 接口的吞吐量会大幅度提高（因为未做真正实际调用，接口RT会非常低）【异步】

候选者：2. 即便有大批量的消息调用接口都不会让系统受到影响（流量由消息队列承载）【削峰】

候选者：又比如说，我这边还有个项目是广告订单归因工程，主要做的事情就是得到订单数据，给各个业务广告计算对应的佣金。

候选者：订单的数据是从消息队列里取出的

候选者：这样设计的好处就是：

候选者：1. 交易团队的同学只要把订单消息写到消息队列，该订单数据的Topic由各个业务方自行消费使用【解耦】【异步】

候选者：2. 即便下单QPS猛增，对下游业务无太大的感知（因为下游业务只消费消息队列的数据，不会直接影响到机器性能）【削峰】

面试官：嗯，那我想问下，你觉得为什么消息队列能到削峰？

面试官：或者换个问法，为什么Kafka能承载这么大的QPS？

候选者：消息队列「最核心」的功能就是把生产的数据存储起来，然后给各个业务把数据再读取出来。

候选者：跟我们处理请求时不一样：在业务处理时可能会调别人的接口，可能会需要去查数据库…等等等一系列的操作才行

候选者：像Kafka在「存储」和「读取」这个过程中又做了很多的优化

候选者：举几个例子，比如说：

候选者：我们往一个Topic发送消息或者读取消息时，实际内部是多个Partition在处理【并行】

候选者：在存储消息时，Kafka内部是顺序写磁盘的，并且利用了操作系统的缓冲区来提高性能【append+cache】

候选者：在读写数据中也减少CPU拷贝文件的次数【零拷贝】

面试官：嗯，你既然提到减少CPU拷贝文件的次数，可以给我说下这项技术吗？

候选者：嗯，可以的，其实就是零拷贝技术。

候选者：比如我们正常调用read函数时，会发生以下的步骤:

候选者：1. DMA把磁盘的拷贝到读内核缓存区

候选者：2. CPU把读内核缓冲区的数据拷贝到用户空间

候选者：正常调用write函数时，会发生以下的步骤：

候选者: 1. CPU把用户空间的数据拷贝到Socket内核缓存区

候选者: 2. DMA把Socket内核缓冲区的数据拷贝到网卡

候选者：可以发现完成「一次读写」需要2次DMA拷贝，2次CPU拷贝。而DMA拷贝是省不了的，所谓的零拷贝技术就是把CPU的拷贝给省掉

候选者：并且为了避免用户进程直接操作内核，保证内核安全，应用程序在调用系统函数时，会发生上下文切换（上述的过程一共会发生4次）

候选者：目前零拷贝技术主要有：mmap和sendfile，这两种技术会一定程度下减少上下文切换和CPU的拷贝

候选者：比如说：mmap是将读缓冲区的地址和用户空间的地址进行映射，实现读内核缓冲区和应用缓冲区共享

候选者：从而减少了从读缓冲区到用户缓冲区的一次CPU拷贝

候选者：使用mmap的后一次读写就可以简化为：

候选者：一、DMA把硬盘数据拷贝到读内核缓冲区。

候选者：二、CPU把读内核缓存区拷贝至Socket内核缓冲区。

候选者：三、DMA把Socket内核缓冲区拷贝至网卡

候选者：由于读内核缓冲区与用户空间做了映射，所以会省了一次CPU拷贝

候选者：而sendfile+DMA Scatter/Gather则是把读内核缓存区的文件描述符/长度信息发到Socket内核缓冲区，实现CPU零拷贝

候选者：使用sendfile+DMA Scatter/Gather一次读写就可以简化为：

候选者：一、DMA把硬盘数据拷贝至读内核缓冲区。

候选者：二、CPU把读缓冲区的文件描述符和长度信息发到Socket缓冲区。

候选者：三、DMA根据文件描述符和数据长度从读内核缓冲区把数据拷贝至网卡

候选者：回到Kafka上

候选者：从Producer->Broker，Kafka是把网卡的数据持久化硬盘，用的是mmap（从2次CPU拷贝减至1次）

候选者：从Broker->Consumer，Kafka是从硬盘的数据发送至网卡，用的是sendFile（实现CPU零拷贝）

面试官：我稍微打断下，我还有点事忙，我总结下你说的话吧

面试官：你用Kafka的原因是为了异步、削峰、解耦

面试官：Kafka能这么快的原因就是实现了并行、充分利用操作系统cache、顺序写和零拷贝

面试官：没错吧？

候选者：嗯



